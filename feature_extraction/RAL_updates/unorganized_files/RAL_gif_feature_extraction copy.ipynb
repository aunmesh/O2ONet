{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotation file\n",
    "# Consider a particular annotation\n",
    "# Load the corresponding gif\n",
    "# Track the bounding boxes\n",
    "# Repurpose the IKEA-ASM feature extraction code to extract the features\n",
    "# Will need to implement the code for I3D network or repurpose the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotation file\n",
    "anno_path = '/workspace/work/misc/O2ONet/data/annotations_minus_unavailable_yt_vids.pkl'\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "f = open(anno_path, 'rb')\n",
    "anno = pkl.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracker with recovery\n",
    "def tracker(frames, main_bbox_tb):\n",
    "    import cv2\n",
    "    import sys\n",
    "    \n",
    "    image_height, image_width,_ = frames[0].shape\n",
    "\n",
    "    main_bbox_wh = (\n",
    "                    main_bbox_tb[0], \n",
    "                    main_bbox_tb[1],\n",
    "                    main_bbox_tb[2]-main_bbox_tb[0],\n",
    "                    main_bbox_tb[3]-main_bbox_tb[1]\n",
    "                    )\n",
    "    (major_ver, minor_ver, subminor_ver) = cv2.__version__.split('.')\n",
    "\n",
    "\n",
    "    # Set up tracker.\n",
    "    # Instead of MIL, you can also use\n",
    "\n",
    "    tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "    tracker_type = tracker_types[-1]\n",
    "\n",
    "    if int(minor_ver) < 3:\n",
    "        tracker = cv2.Tracker_create(tracker_type)\n",
    "    else:\n",
    "        if tracker_type == 'BOOSTING':\n",
    "            tracker = cv2.TrackerBoosting_create()\n",
    "            tracker_rev = cv2.TrackerBoosting_create()\n",
    "        if tracker_type == 'MIL':\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "            tracker_rev = cv2.TrackerMIL_create()\n",
    "        if tracker_type == 'KCF':\n",
    "            tracker = cv2.TrackerKCF_create()\n",
    "            tracker_rev = cv2.TrackerKCF_create()\n",
    "        if tracker_type == 'TLD':\n",
    "            tracker = cv2.legacy_TrackerTLD.create()\n",
    "            tracker_rev = cv2.legacy_TrackerTLD.create()\n",
    "        if tracker_type == 'MEDIANFLOW':\n",
    "            tracker = cv2.legacy_TrackerMedianFlow.create()\n",
    "            tracker_rev = cv2.legacy_TrackerMedianFlow.create()\n",
    "        if tracker_type == 'GOTURN':\n",
    "            tracker = cv2.TrackerGOTURN_create()\n",
    "            tracker_rev = cv2.TrackerGOTURN_create()\n",
    "        if tracker_type == 'MOSSE':\n",
    "            tracker = cv2.legacy_TrackerMOSSE.create()\n",
    "            tracker_rev = cv2.legacy_TrackerMOSSE.create()\n",
    "        if tracker_type == \"CSRT\":\n",
    "            tracker = cv2.TrackerCSRT_create()\n",
    "            tracker_rev = cv2.TrackerCSRT_create()\n",
    "\n",
    "    num_frames = len(frames)\n",
    "\n",
    "    central_index = int((num_frames - 1)/2)\n",
    "    window_size = int(num_frames/2)\n",
    "\n",
    "    central_frame = frames[central_index]\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    \n",
    "    ok = tracker.init(central_frame, main_bbox_wh)\n",
    "    bboxes_forward = []\n",
    "\n",
    "    for i in range(window_size):\n",
    "\n",
    "        # Read a new frame\n",
    "        frame = frames[central_index + 1 + i]        \n",
    "\n",
    "        # Update tracker\n",
    "        ok, bbox_wh = tracker.update(frame)\n",
    "        if not ok:\n",
    "            print(bbox_wh)\n",
    "        # add to the bbox list\n",
    "        if ok:\n",
    "            bbox_tb = [ bbox_wh[0], bbox_wh[1], bbox_wh[0] + bbox_wh[2], bbox_wh[1] + bbox_wh[3] ]\n",
    "            import numpy as np\n",
    "\n",
    "            bbox_tb[0], bbox_tb[2] = np.clip(bbox_tb[0],0, image_width-1), np.clip(bbox_tb[2],0, image_width-1)\n",
    "            bbox_tb[1], bbox_tb[3] = np.clip(bbox_tb[1],0, image_height-1), np.clip(bbox_tb[3],0, image_height-1)\n",
    "\n",
    "            bboxes_forward.append(bbox_tb)\n",
    "            # # Tracking success\n",
    "            # p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            # p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            # cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else :\n",
    "            print(\"Tracking Failure\")\n",
    "            if len(bboxes_forward) > 0:\n",
    "                bboxes_forward.append(bboxes_forward[-1])\n",
    "            else:\n",
    "                bboxes_forward.append(main_bbox_tb)\n",
    "            # bbox_wh = bboxes\n",
    "            # return 0\n",
    "            # Tracking failure\n",
    "            # cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    ok = tracker_rev.init(central_frame, main_bbox_wh)\n",
    "    bboxes_backward = []\n",
    "    for i in range(window_size):\n",
    "        \n",
    "        # Read a new frame\n",
    "        frame = frames[central_index - 1 - i]        \n",
    "        \n",
    "        # Update tracker\n",
    "        ok, bbox_wh = tracker_rev.update(frame)\n",
    "\n",
    "        # Add to the bbox list\n",
    "        if ok:\n",
    "            bbox_tb = [ bbox_wh[0], bbox_wh[1], bbox_wh[0] + bbox_wh[2], bbox_wh[1] + bbox_wh[3] ]\n",
    "\n",
    "            bbox_tb[0], bbox_tb[2] = np.clip(bbox_tb[0],0, image_width-1), np.clip(bbox_tb[2],0, image_width-1)\n",
    "            bbox_tb[1], bbox_tb[3] = np.clip(bbox_tb[1],0, image_height-1), np.clip(bbox_tb[3],0, image_height-1)\n",
    "\n",
    "            bboxes_backward.append(bbox_tb)\n",
    "            # # Tracking success\n",
    "            # p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            # p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            # cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else:\n",
    "            print(\"Tracking Failure\")\n",
    "            if len(bboxes_backward) > 0:\n",
    "                bboxes_backward.append(bboxes_backward[-1])\n",
    "            else:\n",
    "                bboxes_backward.append(main_bbox_tb)\n",
    "            # return 0\n",
    "            # Tracking failure\n",
    "            # cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    del tracker\n",
    "    del tracker_rev\n",
    "    bboxes_backward_reversed = bboxes_backward[-1::-1]\n",
    "    all_bbox = bboxes_backward_reversed + [main_bbox_tb] + bboxes_forward\n",
    "    \n",
    "    return all_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to generate features what we need now is the code to do it.\n",
    "the code works according to x,y,w,h\n",
    "what should be targeted - feature generation code for one gif.\n",
    "the feature is a dictionary. has the following fields\n",
    "metadata, relations, bboxes.\n",
    "\n",
    "image metadata has to be included\n",
    "then there are other keys: relative features, vgg_feature, bbox_features, motion features, i3d features \n",
    "how to go about doing this.\n",
    "\n",
    "All of the relative features need to be generated - like ikea asm.\n",
    "\n",
    "\n",
    "create a function which takes an annotation and generates it's features and returns it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Geometric Feature ( based on bbox dimensions )\n",
    "def geometric_feature(bbox, im_width, im_height):\n",
    "    '''\n",
    "    In Modeling Context Between Objects for Referring Expression Understanding, ECCV 2016\n",
    "    [x_min/W, y_min/H, x_max/W, y_max/H, bbox_area/image_area]\n",
    "    \n",
    "    The annotation are given in Image Coordinate system (X is horizontal & Y is vertical ,(0,0) top left)\n",
    "    The features are calculated in Image Coordinate System as well\n",
    "    '''\n",
    "    x_min = bbox[0]   \n",
    "    y_min = bbox[1]\n",
    "\n",
    "    x_max = bbox[2]\n",
    "    y_max = bbox[3]\n",
    "\n",
    "    bbox_width = x_max - x_min\n",
    "    bbox_height = y_max - y_min\n",
    "    \n",
    "    area_bbox = bbox_width * bbox_height\n",
    "    area_image = im_width * im_height\n",
    "    \n",
    "    feature = [x_min/im_width, y_min/im_height, x_max/im_width, y_max/im_height, area_bbox/area_image]\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    feature = np.asarray(feature, dtype=np.float32)\n",
    "    feature = torch.from_numpy(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2d cnn based deep bbox features\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models_torchvision\n",
    "\n",
    "class ImageFeatureExtractor(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Object feature extractor\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, submodule, layer, device, deep_net):\n",
    "    \n",
    "        \"\"\"\n",
    "        input the object detector module and the layer\n",
    "        number on which we want to extract features\n",
    "        \"\"\"\n",
    "        \n",
    "        super(ImageFeatureExtractor, self).__init__()\n",
    "        \n",
    "        self.pretrain_model = submodule\n",
    "        self.layer = layer\n",
    "        \n",
    "        if deep_net == 'resnet50_fpn':\n",
    "    \n",
    "            self.layer_list = list(self.pretrain_model._modules['backbone']._modules['body']._modules.keys())\n",
    "            layer_generator = self.pretrain_model._modules['backbone']._modules['body'].named_children()\n",
    "            self.transform_module = self.pretrain_model._modules['transform']\n",
    "\n",
    "        if deep_net == 'resnet152':\n",
    "\n",
    "            model = models_torchvision.resnet152(pretrained=True)\n",
    "            self.feature_extract_net = nn.Sequential(*list(model.children())[0:8])\n",
    "            self.feature_extract_net = self.feature_extract_net.eval()\n",
    "            self.pretrain_model = None\n",
    "\n",
    "            from torchvision import transforms\n",
    "            self.transform_module = transforms.Compose([\n",
    "                                                        transforms.ToTensor(),\n",
    "                                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                                            std=[0.229, 0.224, 0.225]),\n",
    "                                                        ])\n",
    "            return\n",
    "\n",
    "        if deep_net == 'vgg16':\n",
    "    \n",
    "            self.layer_list = list(self.pretrain_model._modules['features']._modules.keys())\n",
    "            layer_generator = self.pretrain_model._modules['features'].named_children()\n",
    "            self.transform_module = None\n",
    "\n",
    "        output_layer = self.layer_list[self.layer]\n",
    "        # just change the number of the layer to get the output\n",
    "        self.children_list = []\n",
    "        \n",
    "\n",
    "        for (name, comp_layer) in layer_generator:\n",
    "            self.children_list.append(comp_layer)\n",
    "            if name == output_layer:\n",
    "                break\n",
    "        \n",
    "        self.feature_extract_net = nn.Sequential(*self.children_list).to(device)\n",
    "        self.feature_extract_net = self.feature_extract_net.eval()\n",
    "        self.pretrain_model = None\n",
    "        \n",
    "    def forward(self, image):\n",
    "        \n",
    "        if self.transform_module:\n",
    "\n",
    "            transformation = self.transform_module(image)[0]\n",
    "            shape = transformation.image_sizes[0]\n",
    "            transformed_image = transformation.tensors\n",
    "            image = transformed_image[:,:,:shape[0], :shape[1]]\n",
    "        \n",
    "        feature = self.feature_extract_net(image)\n",
    "        del image\n",
    "        return feature\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Doesn't need correction\n",
    "def extract_image_deep_feature_faster(image, feature_extractor, device):\n",
    "\n",
    "    image = image.astype('float32')\n",
    "    \n",
    "    image = np.swapaxes(image, 0, 2)\n",
    "    image = np.swapaxes(image, 1, 2)\n",
    "    image = np.expand_dims(image, 0)\n",
    "    \n",
    "    image_tensor = torch.from_numpy(image).to(device)\n",
    "    image_feature = feature_extractor(image_tensor)\n",
    "    del image_tensor\n",
    "    return image_feature\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# Doesn't need correction\n",
    "def roi_align(feature_map, boxes):\n",
    "    \n",
    "    pooler = torchvision.ops.RoIAlign(output_size=(7, 7), spatial_scale = 1.0, sampling_ratio=1)\n",
    "    boxes_list = [boxes]\n",
    "    output = pooler(feature_map, boxes_list)\n",
    "\n",
    "    return output\n",
    "\n",
    "import torch.nn.functional as F \n",
    "import torch\n",
    "\n",
    "# Corrected\n",
    "def extract_bbox_deep_features_faster(image, bboxes, im_shape, fmap, device):\n",
    "    '''\n",
    "    bboxes: tensor with bbox coords\n",
    "    '''\n",
    "    image = image.astype('float32')\n",
    "    \n",
    "    # if feature_extractor != None:\n",
    "    #     fmap = extract_image_deep_feature_faster(image, feature_extractor, device)\n",
    "    \n",
    "    im_width_annotation = im_shape[0]\n",
    "    im_height_annotation = im_shape[1]\n",
    "\n",
    "    # boxes_list = []\n",
    "    # num_boxes = int(bboxes.shape[0])\n",
    "    # for i in range(num_boxes):\n",
    "    #     temp_bbox = bboxes[i]\n",
    "    #     boxes_list.append(temp_bbox)\n",
    "\n",
    "    fmap_device = fmap.device\n",
    "\n",
    "    im_height, im_width, _ = image.shape\n",
    "    # im_scale_width, im_scale_height = (im_width*1.0)/im_width_annotation, (im_height*1.0)/im_height_annotation\n",
    "    \n",
    "    _, fmap_height, fmap_width, __ = fmap.shape\n",
    "    fmap_scale_width, fmap_scale_height = (fmap_width*1.0)/im_width_annotation, (fmap_height*1.0)/im_height_annotation\n",
    "    im_size = (im_width, im_height)\n",
    "\n",
    "    # boxes = np.asarray(boxes_list, dtype='float32')\n",
    "    # boxes = torch.from_numpy(boxes)\n",
    "\n",
    "    # print(annotation['objects_coco'])\n",
    "\n",
    "    # scaling of bbox coordinates according to the resized fmap\n",
    "    from copy import copy as copy\n",
    "    boxes = copy(bboxes)\n",
    "    \n",
    "    boxes[:,0] *= fmap_scale_width\n",
    "    boxes[:,2] *= fmap_scale_width\n",
    "    boxes[:,1] *= fmap_scale_height\n",
    "    boxes[:,3] *= fmap_scale_height\n",
    "    \n",
    "    boxes = boxes.to(fmap_device)\n",
    "    \n",
    "    bbox_features = roi_align(fmap, boxes)\n",
    "    bbox_features = F.avg_pool2d(bbox_features, (7,7)).squeeze(2).squeeze(2)\n",
    "        \n",
    "    return bbox_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mIoU and distance\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Corrected\n",
    "def calculate_iou(box_1, box_2):\n",
    "\n",
    "    '''\n",
    "    boxes in [min_x, min_y, max_x, max_y] format\n",
    "    '''\n",
    "    # if torch.sum(box_1 == box_2) == 4:\n",
    "    # return 1\n",
    "\n",
    "    b1_min_x, b1_min_y = box_1[0], box_1[1]\n",
    "    b1_max_x, b1_max_y = box_1[2], box_2[3]\n",
    "\n",
    "    b2_min_x, b2_min_y = box_2[0], box_2[1]\n",
    "    b2_max_x, b2_max_y = box_2[2], box_2[3]\n",
    "\n",
    "\n",
    "    b1 = [[b1_min_x, b1_min_y], [b1_min_x, b1_max_y], [b1_max_x, b1_max_y], [b1_max_x, b1_min_y]]\n",
    "    b2 = [[b2_min_x, b2_min_y], [b2_min_x, b2_max_y], [b2_max_x, b2_max_y], [b2_max_x, b2_min_y]]\n",
    "\n",
    "    poly_1 = Polygon(b1)\n",
    "    poly_2 = Polygon(b2)\n",
    "\n",
    "    i_area = poly_1.intersection(poly_2).area\n",
    "    u_area = poly_1.union(poly_2).area\n",
    "    \n",
    "    iou = i_area / u_area\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# Corrected\n",
    "def calculate_distance_normalized(box_1, box_2, im_width, im_height):\n",
    "    \n",
    "    '''\n",
    "    boxes in [min_x, min_y, max_x, max_y] format\n",
    "    '''\n",
    "\n",
    "    b1_c_x = (box_1[0] + box_1[2]) * 0.5\n",
    "    b1_c_y = (box_1[1] + box_1[3]) * 0.5\n",
    "\n",
    "    b2_c_x = (box_2[0] + box_2[2]) * 0.5\n",
    "    b2_c_y = (box_2[1] + box_2[3]) * 0.5\n",
    "\n",
    "    b1_x, b1_y = b1_c_x/im_width, b1_c_y/im_height\n",
    "    b2_x, b2_y = b2_c_x/im_width, b2_c_y/im_height\n",
    "    \n",
    "    # normalized distance in 0 to 1\n",
    "    dis = np.sqrt( (b1_x-b2_x)**2 + (b1_y-b2_y)**2 ) / np.sqrt(2)\n",
    "\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For relative spatial features\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Corrected\n",
    "def box_deltas(subject_box, object_box):\n",
    "    '''\n",
    "    boxes in [centre_x, centre_y, width, height] format\n",
    "    '''\n",
    "\n",
    "    s_width = subject_box[2] - subject_box[0]\n",
    "    s_height = subject_box[3] - subject_box[1]\n",
    "    \n",
    "    o_width = object_box[2] - object_box[0]\n",
    "    o_height = object_box[3] - object_box[1]\n",
    "\n",
    "    s_centre_x = subject_box[0] + (s_width/2)\n",
    "    s_centre_y = subject_box[1] + (s_height/2)\n",
    "\n",
    "    o_centre_x = object_box[0] + (o_width/2)\n",
    "    o_centre_y = object_box[1] + (o_height/2)\n",
    "    \n",
    "    t_so_x = (s_centre_x - o_centre_x)/s_width\n",
    "    t_so_y = (s_centre_y - o_centre_y)/s_height\n",
    "    \n",
    "    t_so_w = torch.log(s_width/o_width)\n",
    "    t_so_h = torch.log(s_height/o_height)\n",
    "    \n",
    "    t_os_x = (o_centre_x - s_centre_x)/o_width\n",
    "    t_os_y = (o_centre_y - s_centre_y)/o_height\n",
    "    \n",
    "    data = [t_so_x, t_so_y, t_so_w, t_so_h, t_os_x, t_os_y]\n",
    "\n",
    "    return torch.FloatTensor(data)\n",
    "\n",
    "\n",
    "def get_union_box(box_1, box_2):\n",
    "\n",
    "    '''\n",
    "    boxes in [min_x, min_y, max_x, max_y] format\n",
    "    '''\n",
    "\n",
    "    b1_min_x, b1_min_y = box_1[0], box_1[1]\n",
    "    b1_max_x, b1_max_y = box_1[2], box_2[3]\n",
    "\n",
    "    b2_min_x, b2_min_y = box_2[0], box_2[1]\n",
    "    b2_max_x, b2_max_y = box_2[2], box_2[3]\n",
    "\n",
    "    bu_min_x, bu_min_y = min(b1_min_x, b2_min_x), min(b1_min_y, b2_min_y)\n",
    "    bu_max_x, bu_max_y = max(b1_max_x, b2_max_x), max(b1_max_y, b2_max_y)\n",
    "  \n",
    "    return [bu_min_x, bu_min_y, bu_max_x, bu_max_y]\n",
    "\n",
    "def calculate_distance(box_1, box_2):\n",
    "    \n",
    "    '''\n",
    "    boxes in [min_x, min_y, max_x, max_y] format\n",
    "    '''\n",
    "\n",
    "    b1_c_x = (box_1[0] + box_1[2]) * 0.5\n",
    "    b1_c_y = (box_1[1] + box_1[3]) * 0.5\n",
    "\n",
    "    b2_c_x = (box_2[0] + box_2[2]) * 0.5\n",
    "    b2_c_y = (box_2[1] + box_2[3]) * 0.5\n",
    "\n",
    "    dis = np.sqrt( (b1_c_x-b2_c_x)**2 + (b1_c_y-b2_c_y)**2 )\n",
    "\n",
    "    return dis\n",
    "\n",
    "\n",
    "def relative_spatial_features(bbox_1, bbox_2, im_width, im_height):\n",
    "    \n",
    "    bbox_1[0]/=im_width\n",
    "    bbox_1[2]/=im_width\n",
    "    bbox_1[1]/=im_height\n",
    "    bbox_1[3]/=im_height\n",
    "\n",
    "    bbox_2[0]/=im_width\n",
    "    bbox_2[2]/=im_width\n",
    "    bbox_2[1]/=im_height\n",
    "    bbox_2[3]/=im_height\n",
    "    \n",
    "    relative_features = torch.zeros(20, dtype=torch.float32)\n",
    "    \n",
    "    subject_box = bbox_1\n",
    "    object_box = bbox_2\n",
    "\n",
    "    union_box = get_union_box(subject_box, object_box)\n",
    "\n",
    "    relative_features[:6] = box_deltas(subject_box=subject_box, object_box=object_box)\n",
    "    relative_features[6:12] = box_deltas(subject_box=subject_box, object_box=union_box)\n",
    "    relative_features[12:18] = box_deltas(subject_box=object_box, object_box=union_box)\n",
    "    relative_features[18] = calculate_iou(subject_box, object_box)\n",
    "    relative_features[19] = calculate_distance(subject_box, object_box)\n",
    "    \n",
    "    return relative_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:5: UserWarning: The _functional_video module is deprecated. Please use the functional module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:25: UserWarning: The _transforms_video module is deprecated. Please use the transforms module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# For i3d based bbox features\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.ops import MultiScaleRoIAlign\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "import pytorchvideo.models as models\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self, submodule, layer):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.pretrain_model = submodule\n",
    "        self.layer = layer\n",
    "        \n",
    "        self.layer_list = list(self.pretrain_model._modules['blocks']._modules.keys())\n",
    "        print(list(self.pretrain_model._modules['blocks']._modules))\n",
    "        output_layer = self.layer_list[self.layer]  # just change the number of the layer to get the output\n",
    "\n",
    "        self.children_list = []\n",
    "        for (name, comp_layer) in self.pretrain_model._modules['blocks'].named_children():\n",
    "            self.children_list.append(comp_layer)\n",
    "            if name == output_layer:\n",
    "                break\n",
    "        #print(self.children_list)\n",
    "        self.feature_extrac_net = nn.Sequential(*self.children_list)\n",
    "        self.pretrain_model = None\n",
    "\n",
    "    def forward(self, image):\n",
    "        feature = self.feature_extrac_net(image)\n",
    "        return feature\n",
    "\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "from torchvision.transforms._transforms_video import  NormalizeVideo\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    UniformTemporalSubsample\n",
    ")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def read_gif(gif_path):\n",
    "    \"\"\"read gif and return dictionary as key ['video'] and value the tensor of size(CxTxHXW)\"\"\"\n",
    "\n",
    "    video = EncodedVideo.from_path(gif_path)\n",
    "    video = video.get_clip(0, 5) # get_clip fetches the clip from starting time to ending time\n",
    "\n",
    "    return video\n",
    "\n",
    "# Doesn't need correction\n",
    "def roi_align_i3d(feature_map, boxes):\n",
    "    \n",
    "    pooler = torchvision.ops.RoIAlign(output_size=(1, 1), spatial_scale = 1.0, sampling_ratio=1)\n",
    "    boxes_list = [boxes]\n",
    "    output = pooler(feature_map, boxes_list)\n",
    "\n",
    "    return output\n",
    "\n",
    "def roi_align_custom(feature_map, boxes, im_width, im_height):\n",
    "    '''\n",
    "    feature_map : [B,C,T,H,W] B - Batch size (expected 1)\n",
    "    boxes: [N, T, 4] N is number of objects\n",
    "    '''\n",
    "    \n",
    "    fmap_height, fmap_width = feature_map.shape[3:]\n",
    "    boxes[0]/=im_width\n",
    "    boxes[2]/=im_width\n",
    "\n",
    "    boxes[1]/=im_height\n",
    "    boxes[3]/=im_height\n",
    "\n",
    "    boxes[0]*=fmap_width\n",
    "    boxes[2]*=fmap_width\n",
    "\n",
    "    boxes[1]/=fmap_height\n",
    "    boxes[3]/=fmap_height\n",
    "    # output['bboxes'] = torch.zeros(max_num_obj,len(frames),4, dtype=torch.float)\n",
    "    # uniform temporal subsample selects 1,2,3,4,5,6,7,8,9,11\n",
    "    boxes = boxes[:,0:9:2,:]\n",
    "    time_steps = boxes.shape[1]\n",
    "    \n",
    "    roi_align_res = []\n",
    "    for t in range(time_steps):\n",
    "        temp_fmap = feature_map[:,:,t,:,:]\n",
    "        temp_boxes = boxes[:,t,:]\n",
    "        temp_res = roi_align_i3d(temp_fmap, temp_boxes)\n",
    "        roi_align_res.append(temp_res)\n",
    "    \n",
    "    return roi_align_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For motion feature calculation\n",
    "\n",
    "def calculate_motion_feature(geom_feat_1, geom_feat_2):\n",
    "    return geom_feat_1 - geom_feat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Feature Generator\n",
    "import torch\n",
    "def master_feature_generator(annotation, gif_folder, cnn_feature_extractor, i3d_feature_extractor, i3d_transform, device):\n",
    "\n",
    "    # Getting details to load the GIF\n",
    "    yt_id = annotation['metadata']['yt_id']\n",
    "    frame_index = annotation['metadata']['frame no.']\n",
    "\n",
    "    temp = int(int(gif_folder.split('_')[-1])/2)\n",
    "    window_size = temp\n",
    "\n",
    "    # Loading the gif    \n",
    "    # getting the file location\n",
    "    filename = yt_id + '_' + str(frame_index) + '_' + str(window_size) + '.gif'\n",
    "    import os\n",
    "    file_location = os.path.join(gif_folder, filename)\n",
    "    import cv2\n",
    "\n",
    "    # getting the frames\n",
    "    vid = cv2.VideoCapture(file_location)\n",
    "    frames = []\n",
    "    frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for i in range(frame_count):\n",
    "        success, frame = vid.read()\n",
    "        frames.append(frame)\n",
    "    central_frame = frames[window_size]\n",
    "\n",
    "    # Sanity Check    \n",
    "    assert window_size == (len(frames) - 1)/2, \"Possible issue, please check\"\n",
    "\n",
    "    # Output Dictionary\n",
    "    output = {}\n",
    "    output['legend'] = {}\n",
    "    \n",
    "    # Adding the metadata\n",
    "    output['metadata'] = annotation['metadata']\n",
    "    im_height, im_width, _ = frames[0].shape    # NumPy has num rows, num cols which is height and width according to opencv conventions\n",
    "    output['metadata']['frame_width'] = im_width\n",
    "    output['metadata']['frame_height'] = im_height\n",
    "    \n",
    "    # total num of annotated objects \n",
    "    output['num_obj'] = len(list(annotation['bboxes'].keys()))\n",
    "\n",
    "    # saving bbox co-ordinates of objects according to their key in bboxes field\n",
    "    max_num_obj = 12\n",
    "\n",
    "    # bounding box coordinates. not normalized. for image width and height see the metadata\n",
    "    output['bboxes'] = torch.zeros(max_num_obj,len(frames),4, dtype=torch.float)\n",
    "    bbox_keys = annotation['bboxes'].keys()\n",
    "    \n",
    "    for key in bbox_keys:\n",
    "        key_val = int(key)\n",
    "        temp_bbox = annotation['bboxes'][key]['bbox']\n",
    "        \n",
    "        tracked_bboxes = tracker(frames, temp_bbox)\n",
    "        tracked_bboxes = torch.from_numpy(np.asarray(tracked_bboxes, dtype=float))\n",
    "        output['bboxes'][key_val,:,:] = tracked_bboxes\n",
    "\n",
    "    from copy import deepcopy as copy\n",
    "    \n",
    "    # saving relations in tensors\n",
    "\n",
    "    # maps to transform text to indices\n",
    "    cr_map = {'Contact': 0, 'No Contact': 1, 'None of these': 2, '': 2}\n",
    "    lr_map = {'Below/Above': 0, 'Behind/Front': 1, 'Left/Right': 2, 'Inside': 3, 'None of these': 4, '': 4}\n",
    "    mr_map = {'Holding': 0, 'Carrying': 1, 'Adjusting': 2, 'Rubbing': 3, 'Sliding': 4, 'Rotating': 5, 'Twisting': 6,\n",
    "              'Raising': 7, 'Lowering': 8, 'Penetrating': 9, 'Moving Toward': 10, 'Moving Away': 11, \n",
    "              'Negligible Relative Motion': 12, 'None of these': 13, '': 13}\n",
    "\n",
    "    max_num_rels = 15\n",
    "\n",
    "    # tensor storing relations between objects at the corresponding index in object_pairs key\n",
    "    output['lr'] = torch.zeros(max_num_rels, 5)\n",
    "    output['mr'] = torch.zeros(max_num_rels, 14)\n",
    "    output['cr'] = torch.zeros(max_num_rels, 3)\n",
    "    \n",
    "    # object indices between which the corresponding relation is annotated\n",
    "    output['object_pairs'] = torch.zeros(max_num_rels, 2)\n",
    "    \n",
    "    # reading relations and saving them to the tensors\n",
    "    for i, rel in enumerate(annotation['relations']):\n",
    "\n",
    "        object_pairs = rel[0]\n",
    "\n",
    "        mr = rel[1]['mr']\n",
    "        lr = rel[1]['lr']\n",
    "        cr = rel[1]['scr']\n",
    "\n",
    "        for r in mr:\n",
    "            temp_val = mr_map[r]\n",
    "            output['mr'][i, temp_val] = 1\n",
    "        for r in lr:\n",
    "            temp_val = lr_map[r]\n",
    "            output['lr'][i, temp_val] = 1\n",
    "        for r in cr:\n",
    "            temp_val = cr_map[r]\n",
    "            output['cr'][i, temp_val] = 1\n",
    "\n",
    "        output['object_pairs'][i] = torch.from_numpy(np.asarray(object_pairs,dtype=float))\n",
    "\n",
    "    # total number of relations and hence the total number of object pairs as well\n",
    "    output['num_relation'] = len(annotation['relations'])\n",
    "\n",
    "    # Now we have bounding boxes, metadata, relations, number of objects, number of relations\n",
    "    \n",
    "    # image features - cnn features for bboxes, bbox coordinate based features, relative feature, miou, distance,\n",
    "    \n",
    "    # bbox coordinate based features\n",
    "    output['geometric_feature'] = torch.zeros(max_num_obj, len(frames), 5, dtype=float)\n",
    "    \n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "            temp_bbox = copy(output['bboxes'][i, f])\n",
    "            output['geometric_feature'][i, f] = geometric_feature(temp_bbox, im_width, im_height)\n",
    "\n",
    "    # 2d cnn based features for the bounding boxes of central frame\n",
    "    output['object_2d_cnn_feature'] = torch.zeros(max_num_obj, 2048, dtype=float)\n",
    "    \n",
    "    # 2d cnn feature map\n",
    "    temp_fmap = extract_image_deep_feature_faster(central_frame, cnn_feature_extractor, device)\n",
    "    temp_cpu = temp_fmap.detach().cpu()\n",
    "    output['central_frame_2d_cnn_feature_map'] = temp_cpu\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # window_size is also the index of the central frame\n",
    "    central_frame_bboxes = copy(output['bboxes'])[window_size, :output['num_obj']]\n",
    "    temp_bbox_feat = extract_bbox_deep_features_faster(central_frame, central_frame_bboxes, \n",
    "                                             [im_width, im_height], \n",
    "                                             temp_fmap, device)\n",
    "    output['object_2d_cnn_feature'][:output['num_obj'],:] = temp_bbox_feat\n",
    "    del temp_bbox_feat\n",
    "    del temp_fmap\n",
    "    \n",
    "    # miou and distance of bounding boxes\n",
    "    output['iou'] = torch.zeros(max_num_obj, max_num_obj, len(frames))\n",
    "\n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "                for j in range( int(output['num_obj']) ):\n",
    "                    \n",
    "                    temp_box_1 = copy(output['bboxes'])[i, f]\n",
    "                    temp_box_2 = copy(output['bboxes'])[j, f]\n",
    "                    output['iou'][i, j, f] = calculate_iou(temp_box_1, temp_box_2)\n",
    "                        \n",
    "\n",
    "    output['distance'] = torch.zeros(max_num_obj, max_num_obj, len(frames))\n",
    "\n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "                for j in range( int(output['num_obj']) ):\n",
    "\n",
    "                    temp_box_1 = copy(output['bboxes'])[i, f]\n",
    "                    temp_box_2 = copy(output['bboxes'])[j, f]\n",
    "                    output['distance'][i, j, f] = calculate_distance_normalized(temp_box_1, temp_box_2, im_width, im_height)\n",
    "    \n",
    "    # relative features\n",
    "    output['relative_spatial_feature'] = torch.zeros(max_num_obj, max_num_obj, len(frames), 20, dtype=float)\n",
    "\n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "                for j in range( int(output['num_obj']) ):\n",
    "                    \n",
    "                    if i<j:\n",
    "                        temp_box_1 = copy(output['bboxes'])[i, f]\n",
    "                        temp_box_2 = copy(output['bboxes'])[j, f]\n",
    "\n",
    "                    # To keep the features symmetric\n",
    "\n",
    "                    if i>=j:\n",
    "                        temp_box_2 = copy(output['bboxes'])[i, f]\n",
    "                        temp_box_1 = copy(output['bboxes'])[j, f]\n",
    "\n",
    "                    output['relative_spatial_feature'][i, j, f] = relative_spatial_features(temp_box_1, temp_box_2, im_width, im_height)\n",
    "    \n",
    "    # video features - i3d features, motion features, others? \n",
    "    \n",
    "    # i3d features\n",
    "    temp_i3d_video = read_gif(file_location)\n",
    "    temp_i3d_video = i3d_transform(temp_i3d_video)[\"video\"]\n",
    "    temp_i3d_video = temp_i3d_video.unsqueeze(0).to(device)\n",
    "    \n",
    "    temp_i3d_feature_map = i3d_feature_extractor(temp_i3d_video)\n",
    "    output['i3d_feature_map'] = temp_i3d_feature_map.detach().cpu()\n",
    "    \n",
    "    temp_bboxes = copy(output['bboxes']).to(device)\n",
    "    res_i3d_feature_map = roi_align_custom(temp_i3d_feature_map, temp_bboxes, \n",
    "                                           im_width, im_height)\n",
    "    output['object_i3d_feature'] = torch.zeros(window_size, max_num_obj, 2048)\n",
    "    \n",
    "    for i, f in enumerate(res_i3d_feature_map):\n",
    "        output['object_i3d_feature'][i] = f[:, :, 0, 0]\n",
    "    \n",
    "    \n",
    "    # motion features\n",
    "    output['motion_feature'] = torch.zeros(max_num_obj, len(frames), 5)\n",
    "\n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "                    \n",
    "                    temp_geom_feat_1 = output['geometric_feature'][i, f, :]\n",
    "                    if f == 0:\n",
    "                        temp_geom_feat_2 = 0\n",
    "                    else:\n",
    "                        temp_geom_feat_1 = output['geometric_feature'][i, f-1, :]\n",
    "                    \n",
    "                    output['motion_feature'][i, f, :] = calculate_motion_feature(temp_geom_feat_1, temp_geom_feat_2)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6']\n"
     ]
    }
   ],
   "source": [
    "# Loading files required to generate the trackers\n",
    "# Load the annotation file\n",
    "anno_path = '/workspace/work/misc/O2ONet/data/annotations_minus_unavailable_yt_vids.pkl'\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "f = open(anno_path, 'rb')\n",
    "annotations = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "gif_folder = '/workspace/data/data_folder/o2o/gifs_11'\n",
    "\n",
    "# 2d cnn feature extractor\n",
    "import torchvision\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "deep_net = 'resnet152'\n",
    "layer_no = 4\n",
    "if deep_net == 'vgg16':\n",
    "    model = torchvision.models.vgg16(pretrained=True)\n",
    "if deep_net == 'resnet152':\n",
    "    model = torchvision.models.resnet152(pretrained=True)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "cnn_feature_extractor = ImageFeatureExtractor(model, layer_no, device, deep_net).to(device)\n",
    "\n",
    "\n",
    "# i3d feature extractor\n",
    "import pytorchvideo.models as models\n",
    "model_name = \"i3d_r50\"\n",
    "model = torch.hub.load(\"facebookresearch/pytorchvideo:main\", model=model_name, pretrained=True)\n",
    "model = model.to(device)\n",
    "i3d_feature_net = FeatureExtractor(model, 5)\n",
    "\n",
    "# i3d transform\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "i3d_transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(11),\n",
    "            Resize((720,1280)),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "            NormalizeVideo(mean, std)    \n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2056 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/data_folder/o2o/gifs_11_features_ral_v2/0dqx7VOjiJI_1572_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generating all features\n",
    "from tqdm import tqdm as tqdm\n",
    "import os\n",
    "\n",
    "feature_folder = '/workspace/data/data_folder/o2o/gifs_11_features_ral_v2'\n",
    "os.makedirs(feature_folder, exist_ok=True)\n",
    "\n",
    "issues = {}\n",
    "issues['index'] = []\n",
    "issues['exceptions'] = []\n",
    "i = 0\n",
    "\n",
    "for annotation in tqdm(annotations):\n",
    "    \n",
    "    i+=1\n",
    "    # generating location to save the feature dictionary\n",
    "    yt_id = annotation['metadata']['yt_id']\n",
    "    frame_index = annotation['metadata']['frame no.']\n",
    "    window_size = int(int(gif_folder.split('_')[-1])/2)\n",
    "    filename = yt_id + '_' + str(frame_index) + '_' + str(window_size) + '.pt'\n",
    "    file_location = os.path.join(feature_folder, filename)\n",
    "\n",
    "    if os.path.exists(file_location):\n",
    "        continue\n",
    "    \n",
    "    # generating feature dictionary\n",
    "    feature_dict = master_feature_generator(annotation, gif_folder, cnn_feature_extractor, i3d_feature_net, i3d_transform, device)\n",
    "    try:\n",
    "        feature_dict = master_feature_generator(annotation, gif_folder, cnn_feature_extractor, i3d_feature_net, i3d_transform, device)\n",
    "    except Exception as e:\n",
    "        print(\" Issue in \",i)\n",
    "        issues['index'].append(i)\n",
    "        issues['exceptions'].append(e)\n",
    "        break\n",
    "        continue\n",
    "    \n",
    "    # saving the feature dictionary\n",
    "    # torch.save(feature_dict, file_location)\n",
    "    print(file_location)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(feature_dict, file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': [], 'exceptions': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['legend', 'metadata', 'num_obj', 'bboxes', 'lr', 'mr', 'cr', 'object_pairs', 'num_relation', 'geometric_feature', 'object_2d_cnn_feature', 'central_frame_2d_cnn_feature_map', 'iou', 'distance', 'relative_spatial_feature', 'i3d_feature_map', 'object_i3d_feature', 'motion_feature'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [6.4010e-01, 2.3258e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 6.3459e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [1.1605e+00, 1.1156e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 2.1057e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [1.4765e+00, 4.0178e+00, 2.0355e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 5.6996e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 5.3442e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 1.7318e-01,  ..., 2.4116e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 1.8497e-01,  ..., 4.5163e+00,\n",
      "            4.4645e-01, 6.1373e-01]],\n",
      "\n",
      "          [[1.5892e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [3.4488e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4935e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 3.2178e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            1.0317e+00, 1.6567e-02],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0915e+00,\n",
      "            3.1208e+00, 4.4325e-01],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4680e+00,\n",
      "            6.1382e-01, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            2.3952e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            3.0650e-01, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 7.7482e-01,  ..., 2.3365e+00,\n",
      "            1.7146e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1201e+00,\n",
      "            8.9495e-01, 9.4383e-01],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            9.9259e-02, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.4317e-01,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 4.6213e-02],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            2.0877e-01, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 7.0003e-01, 3.1526e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 2.2834e+00, 9.8798e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 1.8945e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 6.8272e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [1.7379e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.5257e+00,\n",
      "            7.2058e+00, 5.5630e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            1.5808e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 2.0474e+00,  ..., 1.6304e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0000e-02,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 3.1423e-02,  ..., 1.4000e-01,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            9.2436e-01, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.8795e-01,\n",
      "            1.3293e+00, 3.9979e-01],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [1.1040e+00, 3.6935e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            1.3176e-01, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.1365e-03,\n",
      "            1.0319e+00, 1.6341e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 2.4205e-01]]],\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            1.7367e+00, 2.9388e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 2.0816e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0048e-02,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 3.3247e-01, 3.4026e-02,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.8328e-01,\n",
      "            2.5875e+00, 1.0804e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 1.6606e-01, 1.7994e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]]]]])\n",
      "torch.Size([1, 2048, 5, 23, 40])\n"
     ]
    }
   ],
   "source": [
    "key = 'i3d_feature_map'\n",
    "print(feature_dict[key])\n",
    "print(feature_dict[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For combining all features into one pickle file\n",
    "\n",
    "def combine_all_pickles(feature_folder):\n",
    "    from glob import glob as glob\n",
    "    files = glob(feature_folder + '/*.pt')\n",
    "    \n",
    "    all_features = []\n",
    "    import torch\n",
    "    \n",
    "    for f in files:\n",
    "        data = torch.load(f)\n",
    "        all_features.append(data)\n",
    "    return all_features\n",
    "\n",
    "feature_folder = '/workspace/data/data_folder/o2o/gifs_11_features'\n",
    "data = combine_all_pickles(feature_folder)\n",
    "\n",
    "# saving_loc = '/workspace/data/data_folder/o2o/all_features/gifs_11/all_features_11.pkl'\n",
    "\n",
    "# import pickle as pickle\n",
    "# f = open(saving_loc, 'wb')\n",
    "# pickle.dump(data, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2050"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating train, test and val splits using previously generated data\n",
    "\n",
    "# train, test, validation split\n",
    "\n",
    "import pickle\n",
    "\n",
    "folder_loc = '/workspace/work/CVPR22/ooi_classification/hidden/gcn/data'\n",
    "\n",
    "train_loc = folder_loc + '/training3.pkl'\n",
    "test_loc = folder_loc + '/testing3.pkl'\n",
    "val_loc = folder_loc + '/validation3.pkl'\n",
    "\n",
    "train_data = pickle.load(open(train_loc,'rb'))\n",
    "val_data = pickle.load(open(val_loc,'rb'))\n",
    "test_data = pickle.load(open(test_loc,'rb'))\n",
    "\n",
    "\n",
    "split_dict = {}\n",
    "\n",
    "for t in train_data:\n",
    "    yt_id = t['metadata']['yt_id']\n",
    "    frame_no = t['metadata']['frame no.']\n",
    "    temp_key = yt_id + '_' + frame_no\n",
    "    split_dict[temp_key] = 'train'\n",
    "    \n",
    "for t in test_data:\n",
    "    yt_id = t['metadata']['yt_id']\n",
    "    frame_no = t['metadata']['frame no.']\n",
    "    temp_key = yt_id + '_' + frame_no\n",
    "    split_dict[temp_key] = 'test'\n",
    "    \n",
    "for t in val_data:\n",
    "    yt_id = t['metadata']['yt_id']\n",
    "    frame_no = t['metadata']['frame no.']\n",
    "    temp_key = yt_id + '_' + frame_no\n",
    "    split_dict[temp_key] = 'val'\n",
    "    \n",
    "saving_path = '/workspace/data/data_folder/o2o/split_dict.pkl'\n",
    "\n",
    "pickle.dump(split_dict, open(saving_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For splitting combined features file into 3 pickle files using split dictionary\n",
    "import pickle as pkl\n",
    "\n",
    "def split(split_dict_path, combined_features_file):\n",
    "\n",
    "\n",
    "    all_features = pkl.load(open(combined_features_file, 'rb'))\n",
    "    split_dict = pkl.load(open(split_dict_path,'rb'))\n",
    "    \n",
    "    train = []\n",
    "    test = []\n",
    "    val = []\n",
    "    \n",
    "    for feat in all_features:\n",
    "        yt_id = feat['metadata']['yt_id']\n",
    "        frame_no = feat['metadata']['frame no.']\n",
    "        temp_key = yt_id + '_' + frame_no\n",
    "        split = split_dict[temp_key]\n",
    "        \n",
    "        if split == 'train':\n",
    "            train.append(feat)\n",
    "        elif split == 'test':\n",
    "            test.append(feat)\n",
    "        elif split == 'val':\n",
    "            val.append(feat)\n",
    "\n",
    "            \n",
    "\n",
    "    saving_folder = '/'.join( combined_features_file.split('/')[:-1] )\n",
    "    import os\n",
    "    \n",
    "    train_file = os.path.join(saving_folder, 'train.pkl')\n",
    "    f = open(train_file, 'wb')\n",
    "    pkl.dump(train, f)\n",
    "    f.close()\n",
    "    \n",
    "    test_file = os.path.join(saving_folder, 'test.pkl')\n",
    "    f = open(test_file, 'wb')\n",
    "    pkl.dump(test, f)\n",
    "    f.close()\n",
    "\n",
    "    val_file = os.path.join(saving_folder, 'val.pkl')\n",
    "    f = open(val_file, 'wb')\n",
    "    pkl.dump(val, f)\n",
    "    f.close()\n",
    "    \n",
    "    return train, test, val\n",
    "\n",
    "split_dict_path = '/workspace/data/data_folder/o2o/split_dict.pkl'\n",
    "combined_features_file = '/workspace/data/data_folder/o2o/all_features/gifs_11/all_features_11.pkl'\n",
    "\n",
    "train, test, val = split(split_dict_path, combined_features_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
