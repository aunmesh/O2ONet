{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to take care of in this feature extraction script\n",
    "\n",
    "1. Using proper transforms in the Neural Networks\n",
    "2. Taking care of using deep copy.\n",
    "3. Using proper layers for feature extraction.\n",
    "4. Normalizing the bounding boxes to lie within 0 to 1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotation file\n",
    "# Consider a particular annotation\n",
    "# Load the corresponding gif\n",
    "# Track the bounding boxes\n",
    "# Repurpose the IKEA-ASM feature extraction code to extract the features\n",
    "# Will need to implement the code for I3D network or repurpose the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotation file\n",
    "anno_path = '/workspace/work/misc/O2ONet/data/annotations_minus_unavailable_yt_vids.pkl'\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "f = open(anno_path, 'rb')\n",
    "anno = pkl.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracker with recovery\n",
    "def tracker(frames, main_bbox_tb):\n",
    "    import cv2\n",
    "    import sys\n",
    "    \n",
    "    image_height, image_width,_ = frames[0].shape\n",
    "\n",
    "    main_bbox_wh = (\n",
    "                    main_bbox_tb[0], \n",
    "                    main_bbox_tb[1],\n",
    "                    main_bbox_tb[2]-main_bbox_tb[0],\n",
    "                    main_bbox_tb[3]-main_bbox_tb[1]\n",
    "                    )\n",
    "    (major_ver, minor_ver, subminor_ver) = cv2.__version__.split('.')\n",
    "\n",
    "\n",
    "    # Set up tracker.\n",
    "    # Instead of MIL, you can also use\n",
    "\n",
    "    tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "    tracker_type = tracker_types[-1]\n",
    "\n",
    "    if int(minor_ver) < 3:\n",
    "        tracker = cv2.Tracker_create(tracker_type)\n",
    "    else:\n",
    "        if tracker_type == 'BOOSTING':\n",
    "            tracker = cv2.TrackerBoosting_create()\n",
    "            tracker_rev = cv2.TrackerBoosting_create()\n",
    "        if tracker_type == 'MIL':\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "            tracker_rev = cv2.TrackerMIL_create()\n",
    "        if tracker_type == 'KCF':\n",
    "            tracker = cv2.TrackerKCF_create()\n",
    "            tracker_rev = cv2.TrackerKCF_create()\n",
    "        if tracker_type == 'TLD':\n",
    "            tracker = cv2.legacy_TrackerTLD.create()\n",
    "            tracker_rev = cv2.legacy_TrackerTLD.create()\n",
    "        if tracker_type == 'MEDIANFLOW':\n",
    "            tracker = cv2.legacy_TrackerMedianFlow.create()\n",
    "            tracker_rev = cv2.legacy_TrackerMedianFlow.create()\n",
    "        if tracker_type == 'GOTURN':\n",
    "            tracker = cv2.TrackerGOTURN_create()\n",
    "            tracker_rev = cv2.TrackerGOTURN_create()\n",
    "        if tracker_type == 'MOSSE':\n",
    "            tracker = cv2.legacy_TrackerMOSSE.create()\n",
    "            tracker_rev = cv2.legacy_TrackerMOSSE.create()\n",
    "        if tracker_type == \"CSRT\":\n",
    "            tracker = cv2.TrackerCSRT_create()\n",
    "            tracker_rev = cv2.TrackerCSRT_create()\n",
    "\n",
    "    num_frames = len(frames)\n",
    "\n",
    "    central_index = int((num_frames - 1)/2)\n",
    "    window_size = int(num_frames/2)\n",
    "\n",
    "    central_frame = frames[central_index]\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    \n",
    "    ok = tracker.init(central_frame, main_bbox_wh)\n",
    "    bboxes_forward = []\n",
    "\n",
    "    for i in range(window_size):\n",
    "\n",
    "        # Read a new frame\n",
    "        frame = frames[central_index + 1 + i]        \n",
    "\n",
    "        # Update tracker\n",
    "        ok, bbox_wh = tracker.update(frame)\n",
    "        if not ok:\n",
    "            print(bbox_wh)\n",
    "        # add to the bbox list\n",
    "        if ok:\n",
    "            bbox_tb = [ bbox_wh[0], bbox_wh[1], bbox_wh[0] + bbox_wh[2], bbox_wh[1] + bbox_wh[3] ]\n",
    "            import numpy as np\n",
    "\n",
    "            bbox_tb[0], bbox_tb[2] = np.clip(bbox_tb[0],0, image_width-1), np.clip(bbox_tb[2],0, image_width-1)\n",
    "            bbox_tb[1], bbox_tb[3] = np.clip(bbox_tb[1],0, image_height-1), np.clip(bbox_tb[3],0, image_height-1)\n",
    "\n",
    "            bboxes_forward.append(bbox_tb)\n",
    "            # # Tracking success\n",
    "            # p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            # p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            # cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else :\n",
    "            print(\"Tracking Failure\")\n",
    "            if len(bboxes_forward) > 0:\n",
    "                bboxes_forward.append(bboxes_forward[-1])\n",
    "            else:\n",
    "                bboxes_forward.append(main_bbox_tb)\n",
    "            # bbox_wh = bboxes\n",
    "            # return 0\n",
    "            # Tracking failure\n",
    "            # cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    ok = tracker_rev.init(central_frame, main_bbox_wh)\n",
    "    bboxes_backward = []\n",
    "    for i in range(window_size):\n",
    "        \n",
    "        # Read a new frame\n",
    "        frame = frames[central_index - 1 - i]        \n",
    "        \n",
    "        # Update tracker\n",
    "        ok, bbox_wh = tracker_rev.update(frame)\n",
    "\n",
    "        # Add to the bbox list\n",
    "        if ok:\n",
    "            bbox_tb = [ bbox_wh[0], bbox_wh[1], bbox_wh[0] + bbox_wh[2], bbox_wh[1] + bbox_wh[3] ]\n",
    "\n",
    "            bbox_tb[0], bbox_tb[2] = np.clip(bbox_tb[0],0, image_width-1), np.clip(bbox_tb[2],0, image_width-1)\n",
    "            bbox_tb[1], bbox_tb[3] = np.clip(bbox_tb[1],0, image_height-1), np.clip(bbox_tb[3],0, image_height-1)\n",
    "\n",
    "            bboxes_backward.append(bbox_tb)\n",
    "            # # Tracking success\n",
    "            # p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            # p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            # cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else:\n",
    "            print(\"Tracking Failure\")\n",
    "            if len(bboxes_backward) > 0:\n",
    "                bboxes_backward.append(bboxes_backward[-1])\n",
    "            else:\n",
    "                bboxes_backward.append(main_bbox_tb)\n",
    "            # return 0\n",
    "            # Tracking failure\n",
    "            # cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    del tracker\n",
    "    del tracker_rev\n",
    "    bboxes_backward_reversed = bboxes_backward[-1::-1]\n",
    "    all_bbox = bboxes_backward_reversed + [main_bbox_tb] + bboxes_forward\n",
    "    \n",
    "    return all_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to generate features what we need now is the code to do it.\n",
    "the code works according to x,y,w,h\n",
    "what should be targeted - feature generation code for one gif.\n",
    "the feature is a dictionary. has the following fields\n",
    "metadata, relations, bboxes.\n",
    "\n",
    "image metadata has to be included\n",
    "then there are other keys: relative features, vgg_feature, bbox_features, motion features, i3d features \n",
    "how to go about doing this.\n",
    "\n",
    "All of the relative features need to be generated - like ikea asm.\n",
    "\n",
    "\n",
    "create a function which takes an annotation and generates it's features and returns it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Geometric Feature ( based on bbox dimensions )\n",
    "def geometric_feature(bbox, im_width, im_height):\n",
    "    '''\n",
    "    In Modeling Context Between Objects for Referring Expression Understanding, ECCV 2016\n",
    "    [x_min/W, y_min/H, x_max/W, y_max/H, bbox_area/image_area]\n",
    "    \n",
    "    The annotation are given in Image Coordinate system (X is horizontal & Y is vertical ,(0,0) top left)\n",
    "    The features are calculated in Image Coordinate System as well\n",
    "    '''\n",
    "    x_min = bbox[0]   \n",
    "    y_min = bbox[1]\n",
    "\n",
    "    x_max = bbox[2]\n",
    "    y_max = bbox[3]\n",
    "\n",
    "    bbox_width = x_max - x_min\n",
    "    bbox_height = y_max - y_min\n",
    "    \n",
    "    area_bbox = bbox_width * bbox_height\n",
    "    area_image = im_width * im_height\n",
    "    \n",
    "    feature = [x_min/im_width, y_min/im_height, x_max/im_width, y_max/im_height, area_bbox/area_image]\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    feature = np.asarray(feature, dtype=np.float32)\n",
    "    feature = torch.from_numpy(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2d cnn based deep bbox features\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models_torchvision\n",
    "\n",
    "import pynvml\n",
    "\n",
    "def get_memory_free_MiB(gpu_index):\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(int(gpu_index))\n",
    "    mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    return mem_info.free // 1024 ** 2\n",
    "\n",
    "\n",
    "class ImageFeatureExtractor(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Object feature extractor\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, submodule, layer, device, deep_net):\n",
    "    \n",
    "        \"\"\"\n",
    "        input the object detector module and the layer\n",
    "        number on which we want to extract features\n",
    "        \"\"\"\n",
    "        \n",
    "        super(ImageFeatureExtractor, self).__init__()\n",
    "        \n",
    "        self.pretrain_model = submodule\n",
    "        self.layer = layer\n",
    "        \n",
    "        model = models_torchvision.resnet152(pretrained=True)\n",
    "        self.feature_extract_net = nn.Sequential(*list(model.children())[0:8])\n",
    "        self.feature_extract_net = self.feature_extract_net.eval()\n",
    "        self.pretrain_model = None\n",
    "\n",
    "        from torchvision import transforms\n",
    "        self.transform_module = transforms.Compose([\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                                        std=[0.229, 0.224, 0.225]),\n",
    "                                                    ])\n",
    "        self.feature_extract_net.eval()\n",
    "\n",
    "\n",
    "    def forward(self, images, device):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print(\"Memory information 1\", get_memory_free_MiB(device.index))\n",
    "            image_tensors = [self.transform_module(image).unsqueeze(0) for image in images]\n",
    "            \n",
    "            print(\"Memory information 2\", get_memory_free_MiB(device.index))\n",
    "            image_concatenated_tensor = torch.cat(image_tensors, dim=0).to(device)\n",
    "            \n",
    "            print(\"Memory information 3\", get_memory_free_MiB(device.index))\n",
    "            feature = self.feature_extract_net(image_concatenated_tensor)\n",
    "            \n",
    "            print(\"Memory information 4\", get_memory_free_MiB(device.index))\n",
    "            feature_cpu = feature.detach().cpu()\n",
    "            \n",
    "            del feature\n",
    "            del image_concatenated_tensor   # preventing memory leak\n",
    "            del image_tensors\n",
    "            \n",
    "            print(\"Memory information 5\", \"clearing tensors\",get_memory_free_MiB(device.index))        \n",
    "            self.feature_extract_net.zero_grad()\n",
    "            print(\"Memory information 6\", \"zero grad\", get_memory_free_MiB(device.index))        \n",
    "\n",
    "        return feature_cpu\n",
    "\n",
    "        \n",
    "    def forward_old(self, images, device):\n",
    "    \n",
    "        print(\"Memory information 1\", get_memory_free_MiB(device.index))\n",
    "        image_tensors = [self.transform_module(image).unsqueeze(0) for image in images]\n",
    "        \n",
    "        print(\"Memory information 2\", get_memory_free_MiB(device.index))\n",
    "        image_concatenated_tensor = torch.cat(image_tensors, dim=0).to(device)\n",
    "        \n",
    "        print(\"Memory information 3\", get_memory_free_MiB(device.index))\n",
    "        feature = self.feature_extract_net(image_concatenated_tensor)\n",
    "        \n",
    "        print(\"Memory information 4\", get_memory_free_MiB(device.index))\n",
    "        feature_cpu = feature.detach().cpu()\n",
    "        \n",
    "        del feature\n",
    "        del image_concatenated_tensor   # preventing memory leak\n",
    "        del image_tensors\n",
    "        \n",
    "        print(\"Memory information 5\", \"clearing tensors\",get_memory_free_MiB(device.index))        \n",
    "        self.feature_extract_net.zero_grad()\n",
    "        print(\"Memory information 6\", \"zero grad\", get_memory_free_MiB(device.index))        \n",
    "        return feature_cpu\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "def extract_image_deep_feature_faster(images, feature_extractor, device):\n",
    "\n",
    "    # image_tensors = [ ToTensor(im) for im in images]\n",
    "    # image_concatenated_tensor = torch.cat(image_tensors, dim=0).to(device)\n",
    "    # image_feature = feature_extractor(image_concatenated_tensor)\n",
    "    image_feature = feature_extractor(images, device)\n",
    "    \n",
    "    # del image_tensors\n",
    "    # del image_concatenated_tensor\n",
    "    return image_feature\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# Doesn't need correction\n",
    "def roi_align(feature_map, boxes):\n",
    "    \n",
    "    pooler = torchvision.ops.RoIAlign(output_size=(7, 7), spatial_scale = 1.0, sampling_ratio=1)\n",
    "    boxes_list = [boxes]\n",
    "    output = pooler(feature_map.unsqueeze(0), boxes_list)\n",
    "\n",
    "    return output\n",
    "\n",
    "import torch.nn.functional as F \n",
    "import torch\n",
    "\n",
    "# Corrected\n",
    "def extract_bbox_deep_features_faster(bboxes, im_shape, fmap, device):\n",
    "    '''\n",
    "    bboxes: tensor with bbox coords\n",
    "    '''\n",
    "    \n",
    "    im_width_annotation, im_height_annotation = im_shape\n",
    "\n",
    "    _, fmap_height, fmap_width, __ = fmap.shape\n",
    "    fmap_scale_width, fmap_scale_height = (fmap_width*1.0)/im_width_annotation, (fmap_height*1.0)/im_height_annotation\n",
    "\n",
    "    fmap_device = fmap.device\n",
    "\n",
    "    from copy import deepcopy as copy\n",
    "    boxes = copy(bboxes)\n",
    "    \n",
    "    boxes[... ,0] *= fmap_scale_width\n",
    "    boxes[... ,2] *= fmap_scale_width\n",
    "    boxes[... ,1] *= fmap_scale_height\n",
    "    boxes[... ,3] *= fmap_scale_height\n",
    "    \n",
    "    boxes = boxes.to(fmap_device)\n",
    "    \n",
    "    num_frames = fmap.shape[0]\n",
    "    all_frame_bbox_features = []\n",
    "    for n in range(num_frames):\n",
    "        bbox_features = roi_align(fmap[n], boxes[n])       \n",
    "        bbox_features = F.avg_pool2d(bbox_features, (7,7)).squeeze(2).squeeze(2)\n",
    "        all_frame_bbox_features.append(bbox_features.unsqueeze(0))\n",
    "    \n",
    "    all_frame_bbox_features = torch.cat(all_frame_bbox_features, dim=0)\n",
    "        \n",
    "    return all_frame_bbox_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mIoU and distance\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Corrected\n",
    "def calculate_iou(box_1, box_2):\n",
    "\n",
    "    '''\n",
    "    boxes in [min_x, min_y, max_x, max_y] format\n",
    "    '''\n",
    "    # if torch.sum(box_1 == box_2) == 4:\n",
    "    # return 1\n",
    "\n",
    "    b1_min_x, b1_min_y = box_1[0], box_1[1]\n",
    "    b1_max_x, b1_max_y = box_1[2], box_2[3]\n",
    "\n",
    "    b2_min_x, b2_min_y = box_2[0], box_2[1]\n",
    "    b2_max_x, b2_max_y = box_2[2], box_2[3]\n",
    "\n",
    "\n",
    "    b1 = [[b1_min_x, b1_min_y], [b1_min_x, b1_max_y], [b1_max_x, b1_max_y], [b1_max_x, b1_min_y]]\n",
    "    b2 = [[b2_min_x, b2_min_y], [b2_min_x, b2_max_y], [b2_max_x, b2_max_y], [b2_max_x, b2_min_y]]\n",
    "\n",
    "    poly_1 = Polygon(b1)\n",
    "    poly_2 = Polygon(b2)\n",
    "\n",
    "    i_area = poly_1.intersection(poly_2).area\n",
    "    u_area = poly_1.union(poly_2).area\n",
    "    \n",
    "    iou = i_area / u_area\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# Corrected\n",
    "def calculate_distance_normalized(box_1, box_2, im_width, im_height):\n",
    "    \n",
    "    '''\n",
    "    boxes in [min_x, min_y, max_x, max_y] format\n",
    "    '''\n",
    "\n",
    "    b1_c_x = (box_1[0] + box_1[2]) * 0.5\n",
    "    b1_c_y = (box_1[1] + box_1[3]) * 0.5\n",
    "\n",
    "    b2_c_x = (box_2[0] + box_2[2]) * 0.5\n",
    "    b2_c_y = (box_2[1] + box_2[3]) * 0.5\n",
    "\n",
    "    b1_x, b1_y = b1_c_x/im_width, b1_c_y/im_height\n",
    "    b2_x, b2_y = b2_c_x/im_width, b2_c_y/im_height\n",
    "    \n",
    "    # normalized distance in 0 to 1\n",
    "    dis = np.sqrt( (b1_x-b2_x)**2 + (b1_y-b2_y)**2 ) / np.sqrt(2)\n",
    "\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For relative spatial features\n",
    "import numpy as np\n",
    "import torch\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Corrected\n",
    "def box_deltas(subject_box, object_box):\n",
    "    '''\n",
    "    boxes in [centre_x, centre_y, width, height] format\n",
    "    '''\n",
    "\n",
    "    s_width = subject_box[2] - subject_box[0]\n",
    "    s_height = subject_box[3] - subject_box[1]\n",
    "    \n",
    "    o_width = object_box[2] - object_box[0]\n",
    "    o_height = object_box[3] - object_box[1]\n",
    "\n",
    "    s_centre_x = subject_box[0] + (s_width/2)\n",
    "    s_centre_y = subject_box[1] + (s_height/2)\n",
    "\n",
    "    o_centre_x = object_box[0] + (o_width/2)\n",
    "    o_centre_y = object_box[1] + (o_height/2)\n",
    "    \n",
    "    t_so_x = (s_centre_x - o_centre_x)/s_width\n",
    "    t_so_y = (s_centre_y - o_centre_y)/s_height\n",
    "    \n",
    "    t_so_w = torch.log(s_width/o_width)\n",
    "    t_so_h = torch.log(s_height/o_height)\n",
    "    \n",
    "    t_os_x = (o_centre_x - s_centre_x)/o_width\n",
    "    t_os_y = (o_centre_y - s_centre_y)/o_height\n",
    "    \n",
    "    data = [t_so_x, t_so_y, t_so_w, t_so_h, t_os_x, t_os_y]\n",
    "\n",
    "    return torch.FloatTensor(data)\n",
    "\n",
    "\n",
    "def get_union_box(box_1, box_2):\n",
    "\n",
    "    '''\n",
    "    boxes in [min_x, min_y, max_x, max_y] format\n",
    "    '''\n",
    "\n",
    "    b1_min_x, b1_min_y = box_1[0], box_1[1]\n",
    "    b1_max_x, b1_max_y = box_1[2], box_2[3]\n",
    "\n",
    "    b2_min_x, b2_min_y = box_2[0], box_2[1]\n",
    "    b2_max_x, b2_max_y = box_2[2], box_2[3]\n",
    "\n",
    "    bu_min_x, bu_min_y = min(b1_min_x, b2_min_x), min(b1_min_y, b2_min_y)\n",
    "    bu_max_x, bu_max_y = max(b1_max_x, b2_max_x), max(b1_max_y, b2_max_y)\n",
    "  \n",
    "    return [bu_min_x, bu_min_y, bu_max_x, bu_max_y]\n",
    "\n",
    "def calculate_distance(box_1, box_2):\n",
    "    \n",
    "    '''\n",
    "    boxes in [min_x, min_y, max_x, max_y] format\n",
    "    '''\n",
    "\n",
    "    b1_c_x = (box_1[0] + box_1[2]) * 0.5\n",
    "    b1_c_y = (box_1[1] + box_1[3]) * 0.5\n",
    "\n",
    "    b2_c_x = (box_2[0] + box_2[2]) * 0.5\n",
    "    b2_c_y = (box_2[1] + box_2[3]) * 0.5\n",
    "\n",
    "    dis = np.sqrt( (b1_c_x-b2_c_x)**2 + (b1_c_y-b2_c_y)**2 )\n",
    "\n",
    "    return dis\n",
    "\n",
    "\n",
    "def relative_spatial_features(bbox_1, bbox_2, im_width, im_height):\n",
    "    \n",
    "    bbox_1[0]/=im_width\n",
    "    bbox_1[2]/=im_width\n",
    "    bbox_1[1]/=im_height\n",
    "    bbox_1[3]/=im_height\n",
    "\n",
    "    bbox_2[0]/=im_width\n",
    "    bbox_2[2]/=im_width\n",
    "    bbox_2[1]/=im_height\n",
    "    bbox_2[3]/=im_height\n",
    "    \n",
    "    relative_features = torch.zeros(20, dtype=torch.float32)\n",
    "    \n",
    "    subject_box = bbox_1\n",
    "    object_box = bbox_2\n",
    "\n",
    "    union_box = get_union_box(subject_box, object_box)\n",
    "\n",
    "    relative_features[:6] = box_deltas(subject_box=subject_box, object_box=object_box)\n",
    "    relative_features[6:12] = box_deltas(subject_box=subject_box, object_box=union_box)\n",
    "    relative_features[12:18] = box_deltas(subject_box=object_box, object_box=union_box)\n",
    "    relative_features[18] = calculate_iou(subject_box, object_box)\n",
    "    relative_features[19] = calculate_distance(subject_box, object_box)\n",
    "    \n",
    "    return relative_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:5: UserWarning: The _functional_video module is deprecated. Please use the functional module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:25: UserWarning: The _transforms_video module is deprecated. Please use the transforms module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# For i3d based bbox features\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.ops import MultiScaleRoIAlign\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "import pytorchvideo.models as models\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self, submodule, layer):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.pretrain_model = submodule\n",
    "        self.layer = layer\n",
    "        \n",
    "        self.layer_list = list(self.pretrain_model._modules['blocks']._modules.keys())\n",
    "        print(list(self.pretrain_model._modules['blocks']._modules))\n",
    "        output_layer = self.layer_list[self.layer]  # just change the number of the layer to get the output\n",
    "\n",
    "        self.children_list = []\n",
    "        for (name, comp_layer) in self.pretrain_model._modules['blocks'].named_children():\n",
    "            self.children_list.append(comp_layer)\n",
    "            if name == output_layer:\n",
    "                break\n",
    "        #print(self.children_list)\n",
    "        self.feature_extrac_net = nn.Sequential(*self.children_list)\n",
    "        self.pretrain_model = None\n",
    "\n",
    "    def forward(self, image):\n",
    "        feature = self.feature_extrac_net(image)\n",
    "        return feature\n",
    "\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "from torchvision.transforms._transforms_video import  NormalizeVideo\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    UniformTemporalSubsample\n",
    ")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def read_gif(gif_path):\n",
    "    \"\"\"read gif and return dictionary as key ['video'] and value the tensor of size(CxTxHXW)\"\"\"\n",
    "\n",
    "    video = EncodedVideo.from_path(gif_path)\n",
    "    video = video.get_clip(0, 5) # get_clip fetches the clip from starting time to ending time\n",
    "\n",
    "    return video\n",
    "\n",
    "# Doesn't need correction\n",
    "def roi_align_i3d(feature_map, boxes):\n",
    "    \n",
    "    pooler = torchvision.ops.RoIAlign(output_size=(1, 1), spatial_scale = 1.0, sampling_ratio=1)\n",
    "    boxes_list = [boxes]\n",
    "    output = pooler(feature_map, boxes_list)\n",
    "\n",
    "    return output\n",
    "\n",
    "def roi_align_custom(feature_map, boxes, im_width, im_height):\n",
    "    '''\n",
    "    feature_map : [B,C,T,H,W] B - Batch size (expected 1)\n",
    "    boxes: [N, T, 4] N is number of objects\n",
    "    '''\n",
    "    \n",
    "    fmap_height, fmap_width = feature_map.shape[3:]\n",
    "    boxes[0]/=im_width\n",
    "    boxes[2]/=im_width\n",
    "\n",
    "    boxes[1]/=im_height\n",
    "    boxes[3]/=im_height\n",
    "\n",
    "    boxes[0]*=fmap_width\n",
    "    boxes[2]*=fmap_width\n",
    "\n",
    "    boxes[1]/=fmap_height\n",
    "    boxes[3]/=fmap_height\n",
    "    # output['bboxes'] = torch.zeros(max_num_obj,len(frames),4, dtype=torch.float)\n",
    "    # uniform temporal subsample selects 1,2,3,4,5,6,7,8,9,11\n",
    "    boxes = boxes[:,0:9:2,:]\n",
    "    time_steps = boxes.shape[1]\n",
    "    \n",
    "    roi_align_res = []\n",
    "    for t in range(time_steps):\n",
    "        temp_fmap = feature_map[:,:,t,:,:]\n",
    "        temp_boxes = boxes[:,t,:]\n",
    "        temp_res = roi_align_i3d(temp_fmap, temp_boxes)\n",
    "        roi_align_res.append(temp_res)\n",
    "    \n",
    "    return roi_align_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For motion feature calculation\n",
    "\n",
    "def calculate_motion_feature(geom_feat_1, geom_feat_2):\n",
    "    return geom_feat_1 - geom_feat_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master Feature Generator\n",
    "import torch\n",
    "def master_feature_generator(annotation, gif_folder, cnn_feature_extractor, \n",
    "                             i3d_feature_extractor, i3d_transform, device):\n",
    "\n",
    "    # Getting details to load the GIF\n",
    "    yt_id = annotation['metadata']['yt_id']\n",
    "    frame_index = annotation['metadata']['frame no.']\n",
    "\n",
    "    temp = int(int(gif_folder.split('_')[-1])/2)\n",
    "    window_size = temp\n",
    "\n",
    "    # Loading the gif    \n",
    "    # getting the file location\n",
    "    filename = yt_id + '_' + str(frame_index) + '_' + str(window_size) + '.gif'\n",
    "    import os\n",
    "    file_location = os.path.join(gif_folder, filename)\n",
    "    import cv2\n",
    "\n",
    "    # getting the frames\n",
    "    vid = cv2.VideoCapture(file_location)\n",
    "    frames = []\n",
    "    frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for i in range(frame_count):\n",
    "        success, frame = vid.read()\n",
    "        frames.append(frame)\n",
    "    central_frame = frames[window_size]\n",
    "\n",
    "    # Sanity Check    \n",
    "    assert window_size == (len(frames) - 1)/2, \"Possible issue, please check\"\n",
    "\n",
    "    # Output Dictionary\n",
    "    output = {}\n",
    "    output['legend'] = {}\n",
    "    \n",
    "    # Adding the metadata\n",
    "    output['metadata'] = annotation['metadata']\n",
    "    im_height, im_width, _ = frames[0].shape    # NumPy has num rows, num cols which is height and width according to opencv conventions\n",
    "    output['metadata']['frame_width'] = im_width\n",
    "    output['metadata']['frame_height'] = im_height\n",
    "    \n",
    "    # total num of annotated objects \n",
    "    output['num_obj'] = len(list(annotation['bboxes'].keys()))\n",
    "\n",
    "    # saving bbox co-ordinates of objects according to their key in bboxes field\n",
    "    max_num_obj = 12\n",
    "\n",
    "    # bounding box coordinates. not normalized. for image width and height see the metadata\n",
    "    output['bboxes'] = torch.zeros(max_num_obj,len(frames),4, dtype=torch.float)\n",
    "    bbox_keys = annotation['bboxes'].keys()\n",
    "    \n",
    "    for key in bbox_keys:\n",
    "        key_val = int(key)\n",
    "        temp_bbox = annotation['bboxes'][key]['bbox']\n",
    "        \n",
    "        tracked_bboxes = tracker(frames, temp_bbox)\n",
    "        tracked_bboxes = torch.from_numpy(np.asarray(tracked_bboxes, dtype=float))\n",
    "        output['bboxes'][key_val,:,:] = tracked_bboxes\n",
    "\n",
    "    from copy import deepcopy as copy\n",
    "    \n",
    "    # saving relations in tensors\n",
    "\n",
    "    # maps to transform text to indices\n",
    "    cr_map = {'Contact': 0, 'No Contact': 1, 'None of these': 2, '': 2}\n",
    "    lr_map = {'Below/Above': 0, 'Behind/Front': 1, 'Left/Right': 2, 'Inside': 3, 'None of these': 4, '': 4}\n",
    "    mr_map = {'Holding': 0, 'Carrying': 1, 'Adjusting': 2, 'Rubbing': 3, 'Sliding': 4, 'Rotating': 5, 'Twisting': 6,\n",
    "              'Raising': 7, 'Lowering': 8, 'Penetrating': 9, 'Moving Toward': 10, 'Moving Away': 11, \n",
    "              'Negligible Relative Motion': 12, 'None of these': 13, '': 13}\n",
    "\n",
    "    max_num_rels = 15\n",
    "\n",
    "    # tensor storing relations between objects at the corresponding index in object_pairs key\n",
    "    output['lr'] = torch.zeros(max_num_rels, 5)\n",
    "    output['mr'] = torch.zeros(max_num_rels, 14)\n",
    "    output['cr'] = torch.zeros(max_num_rels, 3)\n",
    "    \n",
    "    # object indices between which the corresponding relation is annotated\n",
    "    output['object_pairs'] = torch.zeros(max_num_rels, 2)\n",
    "    \n",
    "    # reading relations and saving them to the tensors\n",
    "    for i, rel in enumerate(annotation['relations']):\n",
    "\n",
    "        object_pairs = rel[0]\n",
    "\n",
    "        mr = rel[1]['mr']\n",
    "        lr = rel[1]['lr']\n",
    "        cr = rel[1]['scr']\n",
    "\n",
    "        for r in mr:\n",
    "            temp_val = mr_map[r]\n",
    "            output['mr'][i, temp_val] = 1\n",
    "        for r in lr:\n",
    "            temp_val = lr_map[r]\n",
    "            output['lr'][i, temp_val] = 1\n",
    "        for r in cr:\n",
    "            temp_val = cr_map[r]\n",
    "            output['cr'][i, temp_val] = 1\n",
    "\n",
    "        output['object_pairs'][i] = torch.from_numpy(np.asarray(object_pairs,dtype=float))\n",
    "\n",
    "    # total number of relations and hence the total number of object pairs as well\n",
    "    output['num_relation'] = len(annotation['relations'])\n",
    "\n",
    "    # Now we have bounding boxes, metadata, relations, number of objects, number of relations\n",
    "    \n",
    "    # image features - cnn features for bboxes, bbox coordinate based features, relative feature, miou, distance,\n",
    "    \n",
    "    # bbox coordinate based features\n",
    "    output['geometric_feature'] = torch.zeros(max_num_obj, len(frames), 5, dtype=float)\n",
    "    \n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "            temp_bbox = copy(output['bboxes'][i, f])\n",
    "            output['geometric_feature'][i, f] = geometric_feature(temp_bbox, im_width, im_height)\n",
    "\n",
    "    import pynvml\n",
    "    def get_memory_free_MiB(gpu_index):\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(int(gpu_index))\n",
    "        mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        return mem_info.free // 1024 ** 2\n",
    "    \n",
    "    # 2d cnn feature map\n",
    "    temp_fmap = extract_image_deep_feature_faster( frames, cnn_feature_extractor, device)\n",
    "    \n",
    "    temp_cpu = temp_fmap.detach().cpu()\n",
    "    output['2d_cnn_feature_map'] = temp_cpu\n",
    "    \n",
    "    # # 2d cnn based features for the bounding boxes of central frame\n",
    "\n",
    "    # # window_size is also the index of the central frame\n",
    "    all_frame_bboxes = copy(output['bboxes'])[:, :output['num_obj']]\n",
    "    temp_bbox_feat = extract_bbox_deep_features_faster( all_frame_bboxes, \n",
    "                                                        [im_width, im_height], \n",
    "                                                        temp_fmap, device\n",
    "                                                    )\n",
    "    output['object_2d_cnn_feature'] = torch.zeros(len(frames), max_num_obj, 2048, dtype=float)\n",
    "    # print(\"DEBUG\", output['object_2d_cnn_feature'].shape, temp_bbox_feat.shape)\n",
    "    output['object_2d_cnn_feature'][:, :output['num_obj'], :] = temp_bbox_feat\n",
    "    #output['object_2d_cnn_feature'][:output['num_obj'], :] = temp_bbox_feat\n",
    "    del temp_bbox_feat\n",
    "    del temp_fmap\n",
    "\n",
    "    # miou and distance of bounding boxes\n",
    "    output['iou'] = torch.zeros(max_num_obj, max_num_obj, len(frames))\n",
    "\n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "                for j in range( int(output['num_obj']) ):\n",
    "                    \n",
    "                    temp_box_1 = copy(output['bboxes'])[i, f]\n",
    "                    temp_box_2 = copy(output['bboxes'])[j, f]\n",
    "                    output['iou'][i, j, f] = calculate_iou(temp_box_1, temp_box_2)\n",
    "                        \n",
    "\n",
    "    output['distance'] = torch.zeros(max_num_obj, max_num_obj, len(frames))\n",
    "\n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "                for j in range( int(output['num_obj']) ):\n",
    "\n",
    "                    temp_box_1 = copy(output['bboxes'])[i, f]\n",
    "                    temp_box_2 = copy(output['bboxes'])[j, f]\n",
    "                    output['distance'][i, j, f] = calculate_distance_normalized(temp_box_1, temp_box_2, im_width, im_height)\n",
    "    \n",
    "    # relative features\n",
    "    output['relative_spatial_feature'] = torch.zeros(max_num_obj, max_num_obj, len(frames), 20, dtype=float)\n",
    "\n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "                for j in range( int(output['num_obj']) ):\n",
    "                    \n",
    "                    if i<j:\n",
    "                        temp_box_1 = copy(output['bboxes'])[i, f]\n",
    "                        temp_box_2 = copy(output['bboxes'])[j, f]\n",
    "\n",
    "                    # To keep the features symmetric\n",
    "\n",
    "                    if i>=j:\n",
    "                        temp_box_2 = copy(output['bboxes'])[i, f]\n",
    "                        temp_box_1 = copy(output['bboxes'])[j, f]\n",
    "\n",
    "                    output['relative_spatial_feature'][i, j, f] = relative_spatial_features(temp_box_1, temp_box_2, im_width, im_height)\n",
    "    \n",
    "    # video features - i3d features, motion features, others? \n",
    "    \n",
    "    # i3d features\n",
    "    temp_i3d_video = read_gif(file_location)\n",
    "    temp_i3d_video = i3d_transform(temp_i3d_video)[\"video\"]\n",
    "    temp_i3d_video = temp_i3d_video.unsqueeze(0).to(device)\n",
    "    \n",
    "    temp_i3d_feature_map = i3d_feature_extractor(temp_i3d_video)\n",
    "    output['i3d_feature_map'] = temp_i3d_feature_map.detach().cpu()\n",
    "    \n",
    "    temp_bboxes = copy(output['bboxes']).to(device)\n",
    "    res_i3d_feature_map = roi_align_custom(temp_i3d_feature_map, temp_bboxes, \n",
    "                                           im_width, im_height)[0]\n",
    "    output['object_i3d_feature'] = torch.zeros(window_size, max_num_obj, 2048)\n",
    "    \n",
    "    for i, f in enumerate(res_i3d_feature_map):\n",
    "        output['object_i3d_feature'][i] = f[:, :, 0, 0]\n",
    "    \n",
    "    \n",
    "    # motion features\n",
    "    output['motion_feature'] = torch.zeros(max_num_obj, len(frames), 5)\n",
    "\n",
    "    for f in range(len(frames)):\n",
    "        for i in range( int(output['num_obj']) ):\n",
    "                    temp_geom_feat_1 = output['geometric_feature'][i, f, :]\n",
    "                    if f == 0:\n",
    "                        temp_geom_feat_2 = 0\n",
    "                    else:\n",
    "                        temp_geom_feat_1 = output['geometric_feature'][i, f-1, :]\n",
    "                    \n",
    "                    output['motion_feature'][i, f, :] = calculate_motion_feature(temp_geom_feat_1, \n",
    "                                                                                 temp_geom_feat_2)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6']\n"
     ]
    }
   ],
   "source": [
    "# Loading files required to generate the trackers\n",
    "# Load the annotation file\n",
    "from torchvision.transforms import Resize\n",
    "import pytorchvideo.models as models\n",
    "import torchvision\n",
    "import pickle as pkl\n",
    "anno_path = '/workspace/work/misc/O2ONet/data/annotations_minus_unavailable_yt_vids.pkl'\n",
    "\n",
    "\n",
    "f = open(anno_path, 'rb')\n",
    "annotations = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "gif_folder = '/workspace/data/data_folder/o2o/gifs_11'\n",
    "\n",
    "# 2d cnn feature extractor\n",
    "device = torch.device('cuda:2') if torch.cuda.is_available() else torch.device('cpu')\n",
    "deep_net = 'resnet152'\n",
    "layer_no = 4\n",
    "if deep_net == 'resnet152':\n",
    "    model = torchvision.models.resnet152(pretrained=True)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "cnn_feature_extractor = ImageFeatureExtractor(\n",
    "    model, layer_no, device, deep_net).to(device)\n",
    "\n",
    "\n",
    "# i3d feature extractor\n",
    "model_name = \"i3d_r50\"\n",
    "model = torch.hub.load(\"facebookresearch/pytorchvideo:main\",\n",
    "                       model=model_name, pretrained=True)\n",
    "model = model.to(device)\n",
    "i3d_feature_net = FeatureExtractor(model, 5)\n",
    "\n",
    "# i3d transform\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "i3d_transform = ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(11),\n",
    "            Resize((720, 1280)),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "            NormalizeVideo(mean, std)\n",
    "        ]\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2056 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory information 1 20155\n",
      "Memory information 2 20155\n",
      "Memory information 3 20155\n",
      "Memory information 4 20155\n",
      "Memory information 5 clearing tensors 20155\n",
      "Memory information 6 zero grad 20155\n",
      "Memory information 1 20155\n",
      "Memory information 2 20155\n",
      "Memory information 3 20155\n",
      "Memory information 4 20155\n",
      "Memory information 5 clearing tensors 20155\n",
      "Memory information 6 zero grad 20155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2056 [00:08<2:21:51,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/data_folder/o2o/gifs_11_features_ral_v2/0dqx7VOjiJI_2357_5.pt\n",
      "Memory information 1 20155\n",
      "Memory information 2 20155\n",
      "Memory information 3 20155\n",
      "Memory information 4 20155\n",
      "Memory information 5 clearing tensors 20155\n",
      "Memory information 6 zero grad 20155\n",
      "Memory information 1 19873\n",
      "Memory information 2 19873\n",
      "Memory information 3 19873\n",
      "Memory information 4 19873\n",
      "Memory information 5 clearing tensors 19873\n",
      "Memory information 6 zero grad 19873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2056 [00:17<3:33:35,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/data_folder/o2o/gifs_11_features_ral_v2/0dqx7VOjiJI_2358_5.pt\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2056 [00:26<4:03:23,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/data_folder/o2o/gifs_11_features_ral_v2/0dqx7VOjiJI_2426_5.pt\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2056 [00:34<4:21:50,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/data_folder/o2o/gifs_11_features_ral_v2/0dqx7VOjiJI_3061_5.pt\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2056 [00:43<4:34:04,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/data_folder/o2o/gifs_11_features_ral_v2/0dqx7VOjiJI_3132_5.pt\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2056 [00:50<4:20:38,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/data_folder/o2o/gifs_11_features_ral_v2/0dqx7VOjiJI_3335_5.pt\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n",
      "Memory information 1 19591\n",
      "Memory information 2 19591\n",
      "Memory information 3 19591\n",
      "Memory information 4 19591\n",
      "Memory information 5 clearing tensors 19591\n",
      "Memory information 6 zero grad 19591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2056 [00:53<3:37:20,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/data_folder/o2o/gifs_11_features_ral_v2/4wkxJSj_qf8_3788_5.pt\n",
      "Memory information 1 18971\n",
      "Memory information 2 18971\n",
      "Memory information 3 18971\n",
      "Memory information 4 18971\n",
      "Memory information 5 clearing tensors 18971\n",
      "Memory information 6 zero grad 18971\n",
      "Memory information 1 18971\n",
      "Memory information 2 18971\n",
      "Memory information 3 18971\n",
      "Memory information 4 18971\n",
      "Memory information 5 clearing tensors 18971\n",
      "Memory information 6 zero grad 18971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2056 [01:05<4:28:00,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/data_folder/o2o/gifs_11_features_ral_v2/5KF87CKPpn0_1650_5.pt\n",
      "Memory information 1 18971\n",
      "Memory information 2 18971\n",
      "Memory information 3 18971\n",
      "Memory information 4 18971\n",
      "Memory information 5 clearing tensors 18971\n",
      "Memory information 6 zero grad 18971\n"
     ]
    }
   ],
   "source": [
    "# Generating all features\n",
    "from tqdm import tqdm as tqdm\n",
    "import os\n",
    "\n",
    "feature_folder = '/workspace/data/data_folder/o2o/gifs_11_features_ral_v2'\n",
    "os.makedirs(feature_folder, exist_ok=True)\n",
    "\n",
    "issues = {}\n",
    "issues['index'] = []\n",
    "issues['exceptions'] = []\n",
    "i = 0\n",
    "\n",
    "for annotation in tqdm(annotations):\n",
    "    \n",
    "    i+=1\n",
    "    # generating location to save the feature dictionary\n",
    "    yt_id = annotation['metadata']['yt_id']\n",
    "    frame_index = annotation['metadata']['frame no.']\n",
    "    window_size = int(int(gif_folder.split('_')[-1])/2)\n",
    "    filename = yt_id + '_' + str(frame_index) + '_' + str(window_size) + '.pt'\n",
    "    file_location = os.path.join(feature_folder, filename)\n",
    "\n",
    "    if os.path.exists(file_location):\n",
    "        continue\n",
    "    \n",
    "    # generating feature dictionary\n",
    "    feature_dict = master_feature_generator(annotation, gif_folder, cnn_feature_extractor, i3d_feature_net, i3d_transform, device)\n",
    "    try:\n",
    "        feature_dict = master_feature_generator(annotation, gif_folder, cnn_feature_extractor, i3d_feature_net, i3d_transform, device)\n",
    "    except Exception as e:\n",
    "        print(\" Issue in \",i)\n",
    "        issues['index'].append(i)\n",
    "        issues['exceptions'].append(e)\n",
    "        break\n",
    "        continue\n",
    "    \n",
    "    # saving the feature dictionary\n",
    "    torch.save(feature_dict, file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['legend', 'metadata', 'num_obj', 'bboxes', 'lr', 'mr', 'cr', 'object_pairs', 'num_relation', 'geometric_feature', '2d_cnn_feature_map', 'object_2d_cnn_feature', 'iou', 'distance', 'relative_spatial_feature', 'i3d_feature_map', 'object_i3d_feature', 'motion_feature'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 12, 2048])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict['object_i3d_feature'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4443, 1.1077, 0.9890,  ..., 0.7619, 0.4146, 0.0000],\n",
       "         [1.1334, 0.3365, 0.0827,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.7262, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1078, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0342, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.3816, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3407]],\n",
       "\n",
       "        [[0.1597, 0.2352, 0.0506,  ..., 0.0274, 0.1061, 0.0000],\n",
       "         [0.5920, 0.3749, 0.0453,  ..., 0.7900, 1.7557, 1.1893],\n",
       "         [1.3267, 0.4997, 0.0000,  ..., 1.1698, 2.6663, 1.6567],\n",
       "         ...,\n",
       "         [1.6872, 1.3922, 0.4426,  ..., 0.1249, 0.4384, 0.4619],\n",
       "         [0.7453, 0.8155, 0.2372,  ..., 0.2254, 0.7185, 0.5181],\n",
       "         [0.1310, 0.3335, 0.2070,  ..., 0.2766, 0.8349, 0.6612]],\n",
       "\n",
       "        [[0.1895, 0.2292, 0.0844,  ..., 0.0000, 0.1377, 0.1119],\n",
       "         [0.1932, 0.2550, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.1160, 0.0000,  ..., 0.0000, 0.1528, 0.1413],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.2965, 0.1637, 0.4002],\n",
       "         [0.0646, 0.2874, 0.2746,  ..., 0.1179, 0.1957, 0.4719],\n",
       "         [0.0000, 0.1598, 0.0000,  ..., 0.0000, 0.0000, 0.2082]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2140, 0.3445],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2277],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3300, 0.8672],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0520, 0.4400],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0112, 0.4294],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1411, 0.0952]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0646],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3680, 0.2005],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict['2d_cnn_feature_map'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(feature_dict, file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': [], 'exceptions': []}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['legend', 'metadata', 'num_obj', 'bboxes', 'lr', 'mr', 'cr', 'object_pairs', 'num_relation', 'geometric_feature', 'object_2d_cnn_feature', 'central_frame_2d_cnn_feature_map', 'iou', 'distance', 'relative_spatial_feature', 'i3d_feature_map', 'object_i3d_feature', 'motion_feature'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [6.4010e-01, 2.3258e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 6.3459e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [1.1605e+00, 1.1156e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 2.1057e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [1.4765e+00, 4.0178e+00, 2.0355e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 5.6996e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 5.3442e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 1.7318e-01,  ..., 2.4116e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 1.8497e-01,  ..., 4.5163e+00,\n",
      "            4.4645e-01, 6.1373e-01]],\n",
      "\n",
      "          [[1.5892e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [3.4488e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4935e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 3.2178e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            1.0317e+00, 1.6567e-02],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0915e+00,\n",
      "            3.1208e+00, 4.4325e-01],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4680e+00,\n",
      "            6.1382e-01, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            2.3952e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            3.0650e-01, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 7.7482e-01,  ..., 2.3365e+00,\n",
      "            1.7146e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1201e+00,\n",
      "            8.9495e-01, 9.4383e-01],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            9.9259e-02, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.4317e-01,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 4.6213e-02],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            2.0877e-01, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 7.0003e-01, 3.1526e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 2.2834e+00, 9.8798e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 1.8945e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 6.8272e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [1.7379e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.5257e+00,\n",
      "            7.2058e+00, 5.5630e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            1.5808e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 2.0474e+00,  ..., 1.6304e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0000e-02,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 3.1423e-02,  ..., 1.4000e-01,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            9.2436e-01, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.8795e-01,\n",
      "            1.3293e+00, 3.9979e-01],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [1.1040e+00, 3.6935e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            1.3176e-01, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.1365e-03,\n",
      "            1.0319e+00, 1.6341e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 2.4205e-01]]],\n",
      "\n",
      "\n",
      "         [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            1.7367e+00, 2.9388e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 2.0816e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0048e-02,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 3.3247e-01, 3.4026e-02,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "          [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.8328e-01,\n",
      "            2.5875e+00, 1.0804e+00],\n",
      "           ...,\n",
      "           [0.0000e+00, 1.6606e-01, 1.7994e-01,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00],\n",
      "           [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "            0.0000e+00, 0.0000e+00]]]]])\n",
      "torch.Size([1, 2048, 5, 23, 40])\n"
     ]
    }
   ],
   "source": [
    "key = 'i3d_feature_map'\n",
    "print(feature_dict[key])\n",
    "print(feature_dict[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For combining all features into one pickle file\n",
    "\n",
    "def combine_all_pickles(feature_folder):\n",
    "    from glob import glob as glob\n",
    "    files = glob(feature_folder + '/*.pt')\n",
    "    \n",
    "    all_features = []\n",
    "    import torch\n",
    "    \n",
    "    for f in files:\n",
    "        data = torch.load(f)\n",
    "        all_features.append(data)\n",
    "    return all_features\n",
    "\n",
    "feature_folder = '/workspace/data/data_folder/o2o/gifs_11_features'\n",
    "data = combine_all_pickles(feature_folder)\n",
    "\n",
    "# saving_loc = '/workspace/data/data_folder/o2o/all_features/gifs_11/all_features_11.pkl'\n",
    "\n",
    "# import pickle as pickle\n",
    "# f = open(saving_loc, 'wb')\n",
    "# pickle.dump(data, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2050"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For creating train, test and val splits using previously generated data\n",
    "\n",
    "# train, test, validation split\n",
    "\n",
    "import pickle\n",
    "\n",
    "folder_loc = '/workspace/work/CVPR22/ooi_classification/hidden/gcn/data'\n",
    "\n",
    "train_loc = folder_loc + '/training3.pkl'\n",
    "test_loc = folder_loc + '/testing3.pkl'\n",
    "val_loc = folder_loc + '/validation3.pkl'\n",
    "\n",
    "train_data = pickle.load(open(train_loc,'rb'))\n",
    "val_data = pickle.load(open(val_loc,'rb'))\n",
    "test_data = pickle.load(open(test_loc,'rb'))\n",
    "\n",
    "\n",
    "split_dict = {}\n",
    "\n",
    "for t in train_data:\n",
    "    yt_id = t['metadata']['yt_id']\n",
    "    frame_no = t['metadata']['frame no.']\n",
    "    temp_key = yt_id + '_' + frame_no\n",
    "    split_dict[temp_key] = 'train'\n",
    "    \n",
    "for t in test_data:\n",
    "    yt_id = t['metadata']['yt_id']\n",
    "    frame_no = t['metadata']['frame no.']\n",
    "    temp_key = yt_id + '_' + frame_no\n",
    "    split_dict[temp_key] = 'test'\n",
    "    \n",
    "for t in val_data:\n",
    "    yt_id = t['metadata']['yt_id']\n",
    "    frame_no = t['metadata']['frame no.']\n",
    "    temp_key = yt_id + '_' + frame_no\n",
    "    split_dict[temp_key] = 'val'\n",
    "    \n",
    "saving_path = '/workspace/data/data_folder/o2o/split_dict.pkl'\n",
    "\n",
    "pickle.dump(split_dict, open(saving_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For splitting combined features file into 3 pickle files using split dictionary\n",
    "import pickle as pkl\n",
    "\n",
    "def split(split_dict_path, combined_features_file):\n",
    "\n",
    "\n",
    "    all_features = pkl.load(open(combined_features_file, 'rb'))\n",
    "    split_dict = pkl.load(open(split_dict_path,'rb'))\n",
    "    \n",
    "    train = []\n",
    "    test = []\n",
    "    val = []\n",
    "    \n",
    "    for feat in all_features:\n",
    "        yt_id = feat['metadata']['yt_id']\n",
    "        frame_no = feat['metadata']['frame no.']\n",
    "        temp_key = yt_id + '_' + frame_no\n",
    "        split = split_dict[temp_key]\n",
    "        \n",
    "        if split == 'train':\n",
    "            train.append(feat)\n",
    "        elif split == 'test':\n",
    "            test.append(feat)\n",
    "        elif split == 'val':\n",
    "            val.append(feat)\n",
    "\n",
    "            \n",
    "\n",
    "    saving_folder = '/'.join( combined_features_file.split('/')[:-1] )\n",
    "    import os\n",
    "    \n",
    "    train_file = os.path.join(saving_folder, 'train.pkl')\n",
    "    f = open(train_file, 'wb')\n",
    "    pkl.dump(train, f)\n",
    "    f.close()\n",
    "    \n",
    "    test_file = os.path.join(saving_folder, 'test.pkl')\n",
    "    f = open(test_file, 'wb')\n",
    "    pkl.dump(test, f)\n",
    "    f.close()\n",
    "\n",
    "    val_file = os.path.join(saving_folder, 'val.pkl')\n",
    "    f = open(val_file, 'wb')\n",
    "    pkl.dump(val, f)\n",
    "    f.close()\n",
    "    \n",
    "    return train, test, val\n",
    "\n",
    "split_dict_path = '/workspace/data/data_folder/o2o/split_dict.pkl'\n",
    "combined_features_file = '/workspace/data/data_folder/o2o/all_features/gifs_11/all_features_11.pkl'\n",
    "\n",
    "train, test, val = split(split_dict_path, combined_features_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
