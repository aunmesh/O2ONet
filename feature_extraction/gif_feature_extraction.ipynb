{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotation file\n",
    "# Consider a particular annotation\n",
    "# Load the corresponding gif\n",
    "# Track the bounding boxes\n",
    "# Repurpose the IKEA-ASM feature extraction code to extract the features\n",
    "# Will need to implement the code for I3D network or repurpose the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotation file\n",
    "anno_path = '/workspace/work/O2ONet/data/annotations_minus_unavailable_yt_vids.pkl'\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "f = open(anno_path, 'rb')\n",
    "anno = pkl.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tracker(frames, bbox_tb):\n",
    "\n",
    "    import cv2\n",
    "    import sys\n",
    "    \n",
    "    image_width, image_height,_ = frames[1].shape\n",
    "    print(image_width, image_height, _)\n",
    "    \n",
    "    main_bbox_wh = (bbox_tb[0], bbox_tb[1], bbox_tb[2]-bbox_tb[0], bbox_tb[3]-bbox_tb[1])\n",
    "\n",
    "    (major_ver, minor_ver, subminor_ver) = cv2.__version__.split('.')\n",
    "\n",
    "\n",
    "    # Set up tracker.\n",
    "    # Instead of MIL, you can also use\n",
    "\n",
    "    tracker_types = ['BOOSTING', 'MIL','KCF', 'TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "    tracker_type = tracker_types[-2]\n",
    "\n",
    "    if int(minor_ver) < 3:\n",
    "        tracker = cv2.Tracker_create(tracker_type)\n",
    "    else:\n",
    "        if tracker_type == 'BOOSTING':\n",
    "            tracker = cv2.TrackerBoosting_create()\n",
    "            tracker_rev = cv2.TrackerBoosting_create()\n",
    "        if tracker_type == 'MIL':\n",
    "            tracker = cv2.TrackerMIL_create()\n",
    "            tracker_rev = cv2.TrackerMIL_create()\n",
    "        if tracker_type == 'KCF':\n",
    "            tracker = cv2.TrackerKCF_create()\n",
    "            tracker_rev = cv2.TrackerKCF_create()\n",
    "        if tracker_type == 'TLD':\n",
    "            tracker = cv2.TrackerTLD_create()\n",
    "            tracker_rev = cv2.TrackerTLD_create()\n",
    "        if tracker_type == 'MEDIANFLOW':\n",
    "            tracker = cv2.TrackerMedianFlow_create()\n",
    "            tracker_rev = cv2.TrackerMedianFlow_create()\n",
    "        if tracker_type == 'GOTURN':\n",
    "            tracker = cv2.TrackerGOTURN_create()\n",
    "            tracker_rev = cv2.TrackerGOTURN_create()\n",
    "        if tracker_type == 'MOSSE':\n",
    "            tracker = cv2.legacy_TrackerMOSSE.create()\n",
    "            tracker_rev = cv2.legacy_TrackerMOSSE.create()\n",
    "        if tracker_type == \"CSRT\":\n",
    "            tracker = cv2.TrackerCSRT_create()\n",
    "            tracker_rev = cv2.TrackerCSRT_create()\n",
    "\n",
    "    num_frames = len(frames)\n",
    "\n",
    "    central_index = int((num_frames - 1)/2)\n",
    "    window_size = int(num_frames/2)\n",
    "\n",
    "    central_frame = frames[central_index]\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "\n",
    "    ok = tracker.init(central_frame, main_bbox_wh)\n",
    "    bboxes_forward = []\n",
    "\n",
    "    for i in range(window_size):\n",
    "\n",
    "        # Read a new frame\n",
    "        frame = frames[central_index + 1 + i]        \n",
    "\n",
    "        # Update tracker\n",
    "        ok, bbox_wh = tracker.update(frame)\n",
    "\n",
    "        # add to the bbox list\n",
    "        if ok:\n",
    "            bbox_tb = [ bbox_wh[0], bbox_wh[1], bbox_wh[0] + bbox_wh[2], bbox_wh[1] + bbox_wh[3] ]\n",
    "            import numpy as np\n",
    "\n",
    "            bbox_tb[0], bbox_tb[2] = np.clip(bbox_tb[0],0, image_width-1), np.clip(bbox_tb[2],0, image_width-1)\n",
    "            bbox_tb[1], bbox_tb[3] = np.clip(bbox_tb[1],0, image_height-1), np.clip(bbox_tb[3],0, image_height-1)\n",
    "\n",
    "            bboxes_forward.append(bbox_tb)\n",
    "            # # Tracking success\n",
    "            # p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            # p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            # cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else :\n",
    "            print(\"Tracking Failure\")\n",
    "            return 0\n",
    "            # Tracking failure\n",
    "            # cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    # Initialize tracker with first frame and bounding box\n",
    "    ok = tracker_rev.init(central_frame, main_bbox_wh)\n",
    "    bboxes_backward = []\n",
    "    for i in range(window_size):\n",
    "        \n",
    "        # Read a new frame\n",
    "        frame = frames[central_index - 1 - i]        \n",
    "        \n",
    "        # Update tracker\n",
    "        ok, bbox_wh = tracker_rev.update(frame)\n",
    "\n",
    "        # Add to the bbox list\n",
    "        if ok:\n",
    "            bbox_tb = [ bbox_wh[0], bbox_wh[1], bbox_wh[0] + bbox_wh[2], bbox_wh[1] + bbox_wh[3] ]\n",
    "\n",
    "            bbox_tb[0], bbox_tb[2] = np.clip(bbox_tb[0],0, image_width-1), np.clip(bbox_tb[2],0, image_width-1)\n",
    "            bbox_tb[1], bbox_tb[3] = np.clip(bbox_tb[1],0, image_height-1), np.clip(bbox_tb[3],0, image_height-1)\n",
    "\n",
    "            bboxes_backward.append(bbox_tb)\n",
    "            # # Tracking success\n",
    "            # p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            # p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            # cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "        else:\n",
    "            print(\"Tracking Failure\")\n",
    "            return 0\n",
    "            # Tracking failure\n",
    "            # cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "\n",
    "    bboxes_backward_reversed = bboxes_backward[-1::-1]\n",
    "    all_bbox = bboxes_backward_reversed + [bbox_tb] + bboxes_backward_reversed\n",
    "    \n",
    "    return all_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 1280 3\n"
     ]
    }
   ],
   "source": [
    "def visualise_tracking(frames, bboxes):\n",
    "\n",
    "        import cv2\n",
    "        vis_frames = []\n",
    "        \n",
    "        for i, frame in enumerate(frames):\n",
    "\n",
    "            bbox = bboxes[i]\n",
    "            p1 = ( int(bbox[0]), int(bbox[1]) )\n",
    "            p2 = ( int(bbox[2]), int(bbox[3]) )\n",
    "            temp_frame = cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "            rgb_frame = cv2.cvtColor(temp_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            vis_frames.append(rgb_frame)\n",
    "        \n",
    "        import imageio\n",
    "        fps = 4\n",
    "        imageio.mimsave( './visualisation.gif', vis_frames, fps=4)\n",
    "\n",
    "\n",
    "def track_bbox(anno, gif_folder):\n",
    "\n",
    "    bbox = anno['bboxes']['1']['bbox']\n",
    "    \n",
    "    yt_id = anno['metadata']['yt_id']\n",
    "    frame_index = anno['metadata']['frame no.']\n",
    "    window_size = 5\n",
    "    \n",
    "    filename = yt_id + '_' + str(frame_index) + '_' + str(window_size) + '.gif'\n",
    "    import os\n",
    "    file_location = os.path.join(gif_folder, filename)\n",
    "    import cv2\n",
    "    vid = cv2.VideoCapture(file_location)\n",
    "    frames = []\n",
    "\n",
    "    frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    for i in range(frame_count):\n",
    "        success, frame = vid.read()\n",
    "        frames.append(frame)\n",
    "\n",
    "    bboxes = tracker(frames, bbox)\n",
    "    visualise_tracking(frames, bboxes)\n",
    "    return\n",
    "\n",
    "gif_path = '/workspace/data/data_folder/o2o/gifs_11'\n",
    "track_bbox(anno[16], gif_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to generate features what we need now is the code to do it.\n",
    "the code works according to x,y,w,h\n",
    "what should be targeted - feature generation code for one gif.\n",
    "the feature is a dictionary. has the following fields\n",
    "metadata, relations, bboxes.\n",
    "image metadata has to be included\n",
    "then there are other keys: relative features, vgg_feature, bbox_features, motion features, i3d features \n",
    "how to go about doing this.\n",
    "\n",
    "All of the relative features need to be generated - like ikea asm.\n",
    "\n",
    "\n",
    "create a function which takes an annotation and generates it's features and returns it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_feature_generator(annotation, gif_folder):\n",
    "\n",
    "    # Getting details to load the GIF\n",
    "    yt_id = annotation['metadata']['yt_id']\n",
    "    frame_index = annotation['metadata']['frame no.']\n",
    "\n",
    "    temp = int(int(gif_folder.split('_')[-1])/2)\n",
    "    window_size = temp\n",
    "\n",
    "    # Loading the gif    \n",
    "    filename = yt_id + '_' + str(frame_index) + '_' + str(window_size) + '.gif'\n",
    "    import os\n",
    "    file_location = os.path.join(gif_folder, filename)\n",
    "    import cv2\n",
    "    vid = cv2.VideoCapture(file_location)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    frame_count = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    for i in range(frame_count):\n",
    "        success, frame = vid.read()\n",
    "        frames.append(frame)\n",
    "    \n",
    "    im_width, im_height, _ = frames[0].shape    \n",
    "\n",
    "    # Sanity Check    \n",
    "    assert window_size == (len(frames) - 1)/2, \"Possible issue, please check\"\n",
    "\n",
    "    # Output Dictionary\n",
    "    output = {}\n",
    "    output['metadata'] = annotation['metadata']\n",
    "    output['metadata']['frame_width'] = im_width\n",
    "    output['metadata']['frame_height'] = im_height\n",
    "    \n",
    "    output['num_objs'] = len(list(output['bboxes'].keys()))\n",
    "    output['num_relations'] = len(annotation['relations'])\n",
    "\n",
    "    max_num_obj = 12\n",
    "    max_num_relations = 15\n",
    "\n",
    "    import torch\n",
    "    \n",
    "    # Save all the objects according to their key\n",
    "    \n",
    "    output['bboxes'] = torch.zeros(max_num_obj,len(frames),4, dtype=torch.float)\n",
    "    \n",
    "    # output['mr'] = torch.zeros(max_num_relations)\n",
    "    # output['lr'] = torch.zeros(max_num_relations)\n",
    "    # output['scr'] = torch.zeros(max_num_relations)\n",
    "    \n",
    "    # scr_map = {'Contact': 0, 'No Contact': 1, 'None of these': 2, '': 2}\n",
    "\n",
    "    # lr_map = {'Below/Above': 0, 'Behind/Front': 1, 'Left/Right': 2, 'Inside': 3, 'None of these': 4, '': 4}\n",
    "\n",
    "    # mr_map = {'Holding': 0, 'Carrying': 1, 'Adjusting': 2, 'Rubbing': 3, 'Sliding': 4, 'Rotating': 5, 'Twisting': 6,\n",
    "    #           'Raising': 7, 'Lowering': 8, 'Penetrating': 9, 'Moving Toward': 10, 'Moving Away': 11, \n",
    "    #           'Negligible Relative Motion': 12, 'None of these': 13, '': 13}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "266e07f64aa3f1afd9991a0b824d04fa241a0ccb3b0a1eb69e96cbe416527717"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
